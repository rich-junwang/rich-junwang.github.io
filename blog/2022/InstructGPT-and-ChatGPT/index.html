<!DOCTYPE html>
<html lang="">

<!-- Head -->

<head>    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>InstructGPT and ChatGPT | Jun's webpage</title>
    <meta name="author" content="Jun  Wang" />
    <meta name="description" content="tricks and tips" />


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.5.2/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/.css" media="none" id="highlight_theme_light" />

    <!-- Styles -->
    
    <link rel="shortcut icon" href="/assets/img/favicon.png">
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://rich-junwang.github.io//blog/2022/InstructGPT-and-ChatGPT/">
    
    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/.css" media="none" id="highlight_theme_dark" />

    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
    

</head>

<!-- Body -->

<body
  class="fixed-top-nav ">

  <!-- Header --><header>
  <!-- Nav Bar -->
  <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      <a class="navbar-brand title font-weight-lighter" href="https://rich-junwang.github.io//">Jun's webpage</a>
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>

      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">

          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/"></a>
          </li>
          
          <!-- Blog -->
          <li class="nav-item active">
            <a class="nav-link" href="/blog/">blog<span class="sr-only">(current)</span></a>
          </li>

          <!-- Other pages -->

          <!-- Toogle theme mode -->
          <li class="toggle-container">
            <button id="light-toggle" title="Change theme">
              <i class="fas fa-moon"></i>
              <i class="fas fa-sun"></i>
            </button>
          </li>
        </ul>
      </div>
    </div>
  </nav>
</header>

  <!-- Content -->
  <div class="container mt-5">
    <!-- _layouts/post.html -->

<div class="post">

  <header class="post-header">
    <h1 class="post-title">InstructGPT and ChatGPT</h1>
    <p class="post-meta">November 25, 2022</p>
    <!-- <p class="post-tags">
      <a href="/blog/2022"> <i class="fas fa-calendar fa-sm"></i> 2022 </a>
      &nbsp; &middot; &nbsp;
        <a href="/blog/tag/Research">
          <i class="fas fa-hashtag fa-sm"></i> Research</a> &nbsp;
          
      &nbsp; &middot; &nbsp;
        <a href="/blog/category/research">
          <i class="fas fa-tag fa-sm"></i> research</a> &nbsp;
          
    </p> -->
  </header>

  <article class="post-content">
    <p>Recently ChatGPT model has demonstrated remarkable success of large pretrained language model being able to generate coherent, logical and meaningful conversations. While as of this writing, the corresponding paper is still not available yet. In this blog, I’ll dive deep into InstructGPT model to see what’s under the hood of this model.</p>
<h3 id="issues-with-traditional-lm">Issues with Traditional LM</h3>
<p>Language modeling objective is trying to predict next token given all previous tokens. However, when we’re prompting LM in inference time, we hope LM can generate things based on our instructions/intent instead of merely predicting the most likely tokens. This is the so-called <code class="language-plaintext highlighter-rouge">misalignment</code> between training and inference.</p>

<h3 id="solution">Solution</h3>
<p>Using reinforcement learning to learn human feedback. For this purpose, they have to collect a dataset. The way to collect the dataset is as follows:</p>
<ul>
  <li>select some contract labeler</li>
  <li>collect human written prompt-answer pairs. Prompts are either from GPT3 API or from human annotation.</li>
  <li>collect a dataset of human-labeled comparisons between outputs from our models on a larger set of API prompts.</li>
</ul>

<p>The following diagram from the paper demonstrated how these steps unfold during the training.</p>
<p align="center">
    <img alt="make it parse" src="/assets/img/instructgpt.png" width="800">
    <br>
</p>

<p>In summary, there are three steps:</p>
<ul>
  <li>Use labeled data to fine-tune GPT3 model</li>
  <li>Train a reward model</li>
  <li>Use RL to optimize GPT3 parameters</li>
</ul>

<p>In the first step, we got data from annotators and use this data to fine-tune GPT3 model. In the second step, they prepare some questions and GPT3 model gives multiple predictions for each question and annotators are asked to rank the generated predictions. This data is used to train reward model. The reward model is used for prediction and predict which one is most close to human choice. Reward model gives a score and the closer to human choice, the higher of the score.</p>

<p>Finally, use policy-based RM algorithm to do further optimization. The whole process is shown in the diagram below. It uses reward mechanism to train model. The reward can be seen as the loss function in traditional ML training. Reward function is much more versatile than loss function (Think about DotaRL and AlphaGo). The consequence is that reward function may not be differentiable, thus can’t be used for back-propagation. People can sample rewards to proximate this loss function.</p>

<p align="center">
    <img alt="rl" src="/assets/img/lm_rl.png" width="800">
    <br>
    <em>RL algorithm. Image from [4]</em>
    <br>
</p>

<h3 id="ppo">PPO</h3>

<p>From the repo in [4], the three steps of PPO are as follows:</p>

<ul>
  <li>Rollout: The language model generates a response or continuation based on query which could be the start of a sentence.</li>
  <li>Evaluation: The query and response are evaluated with a function, model, human feedback or some combination of them. The important thing is that this process should yield a scalar value for each query/response pair.</li>
  <li>Optimization: In the optimisation step the query/response pairs are used to calculate the log-probabilities of the tokens in the sequences. This is done with the model that is trained and and a reference model, which is usually the pre-trained model before fine-tuning. The KL-divergence between the two outputs is used as an additional reward signal to make sure the generated responses don’t deviate to far from the reference language model. The active language model is then trained with PPO.</li>
</ul>

<p>(To be continued)</p>

<h3 id="references">References</h3>
<p>[1] <a href="https://arxiv.org/pdf/2009.01325.pdf" target="_blank" rel="noopener noreferrer">Learning to summarize from human feedback</a> <br>
[2] <a href="https://arxiv.org/abs/2203.02155" target="_blank" rel="noopener noreferrer">InstructGPT: Training language models to follow instructions with human feedback</a> <br>
[3] <a href="https://arxiv.org/pdf/1909.08593.pdf" target="_blank" rel="noopener noreferrer">Fine-Tuning Language Models from Human Preferences</a> <br>
[4] https://github.com/lvwerra/trl  <br>
[5] https://zhuanlan.zhihu.com/p/590311003  <br>
[6] <a href="https://arxiv.org/abs/2204.07705" target="_blank" rel="noopener noreferrer">Super-natural instructions: generalization via declarative instructions on 1600+ NLP tasks</a>
[7] <a href="https://arxiv.org/abs/2204.05862" target="_blank" rel="noopener noreferrer">Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback</a></p>


  </article>

</div>

    <div class="space"></div>
  </div>

  <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2023 Jun  Wang. Powered by <a href="http://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/rich-junwang" target="_blank" rel="noopener noreferrer">junwang</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>.

      </div>
    </footer>

  <!-- JavaScripts -->
  <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>

  <!-- Bootsrap & MDB scripts -->
  <script async src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.4.4/dist/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
  <script async src="https://cdn.jsdelivr.net/npm/bootstrap@4.5.2/dist/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
  <script async src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
  
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js"></script><!-- Load Common JS -->
  <script defer src="/assets/js/common.js"></script>

  <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

  
</body>

</html>
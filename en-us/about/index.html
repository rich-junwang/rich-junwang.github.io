<!doctype html><html lang=en-us dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>🙋🏻‍♂️About | Jun's Blog</title><meta name=keywords content><meta name=description content="About Me




Hi there, this is Jun Wang. Welcome to my website. I'm an AI researcher. I love programming but I prefer training models to write code for me.. 
I am Staff Research Scientist at ByteDance Seed working on foundational model training. Prior to that I&rsquo;m a Senior Applied Scientist at Amazon, specializing in foundational model pre-training, post-training, and reinforcement learning for complex reasoning tasks. My expertise spans the full stack of large language model (LLM) development, including data curation, pretraining, supervised fine-tuning (SFT), and reinforcement learning with human feedback (RLHF). I have experience training both text and code models. Most recently, I&rsquo;ve been focusing on deep RL for math, code generation tasks.

Opinions are my own and I do not speak for my employer or my team. On this webpage, I'd like to share my study and my
paper reading. Feel free to reach out to me if you have any comments/suggestions"><meta name=author content="Jun"><link rel=canonical href=https://rich-junwang.github.io/en-us/about/><link crossorigin=anonymous href=/assets/css/stylesheet.css rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.js onload=hljs.initHighlightingOnLoad()></script><link rel=icon href=https://rich-junwang.github.io/img/Q.gif><link rel=icon type=image/png sizes=16x16 href=https://rich-junwang.github.io/img/Q.gif><link rel=icon type=image/png sizes=32x32 href=https://rich-junwang.github.io/img/Q.gif><link rel=apple-touch-icon href=https://rich-junwang.github.io/img/Q.gif><link rel=mask-icon href=https://rich-junwang.github.io/img/Q.gif><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en-us href=https://rich-junwang.github.io/en-us/about/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/font-awesome@4.7.0/css/font-awesome.min.css><script src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script><script src=https://cdn.jsdelivr.net/npm/jquery@3.6.3/dist/jquery.min.js></script><script>var _hmt=_hmt||[];(function(){var e,t=document.createElement("script");t.src="",e=document.getElementsByTagName("script")[0],e.parentNode.insertBefore(t,e)})()</script><meta property="og:title" content="🙋🏻‍♂️About"><meta property="og:description" content="About Me




Hi there, this is Jun Wang. Welcome to my website. I'm an AI researcher. I love programming but I prefer training models to write code for me.. 
I am Staff Research Scientist at ByteDance Seed working on foundational model training. Prior to that I&rsquo;m a Senior Applied Scientist at Amazon, specializing in foundational model pre-training, post-training, and reinforcement learning for complex reasoning tasks. My expertise spans the full stack of large language model (LLM) development, including data curation, pretraining, supervised fine-tuning (SFT), and reinforcement learning with human feedback (RLHF). I have experience training both text and code models. Most recently, I&rsquo;ve been focusing on deep RL for math, code generation tasks.

Opinions are my own and I do not speak for my employer or my team. On this webpage, I'd like to share my study and my
paper reading. Feel free to reach out to me if you have any comments/suggestions"><meta property="og:type" content="article"><meta property="og:url" content="https://rich-junwang.github.io/en-us/about/"><meta property="article:section" content><meta property="article:published_time" content="2021-11-06T14:57:28+08:00"><meta property="article:modified_time" content="2021-11-06T14:57:28+08:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="🙋🏻‍♂️About"><meta name=twitter:description content="About Me




Hi there, this is Jun Wang. Welcome to my website. I'm an AI researcher. I love programming but I prefer training models to write code for me.. 
I am Staff Research Scientist at ByteDance Seed working on foundational model training. Prior to that I&rsquo;m a Senior Applied Scientist at Amazon, specializing in foundational model pre-training, post-training, and reinforcement learning for complex reasoning tasks. My expertise spans the full stack of large language model (LLM) development, including data curation, pretraining, supervised fine-tuning (SFT), and reinforcement learning with human feedback (RLHF). I have experience training both text and code models. Most recently, I&rsquo;ve been focusing on deep RL for math, code generation tasks.

Opinions are my own and I do not speak for my employer or my team. On this webpage, I'd like to share my study and my
paper reading. Feel free to reach out to me if you have any comments/suggestions"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"🙋🏻‍♂️About","item":"https://rich-junwang.github.io/en-us/about/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"🙋🏻‍♂️About","name":"🙋🏻‍♂️About","description":"About Me\nHi there, this is Jun Wang. Welcome to my website. I'm an AI researcher. I love programming but I prefer training models to write code for me.. I am Staff Research Scientist at ByteDance Seed working on foundational model training. Prior to that I\u0026rsquo;m a Senior Applied Scientist at Amazon, specializing in foundational model pre-training, post-training, and reinforcement learning for complex reasoning tasks. My expertise spans the full stack of large language model (LLM) development, including data curation, pretraining, supervised fine-tuning (SFT), and reinforcement learning with human feedback (RLHF). I have experience training both text and code models. Most recently, I\u0026rsquo;ve been focusing on deep RL for math, code generation tasks.\nOpinions are my own and I do not speak for my employer or my team. On this webpage, I'd like to share my study and my paper reading. Feel free to reach out to me if you have any comments/suggestions\n","keywords":[],"articleBody":"About Me\nHi there, this is Jun Wang. Welcome to my website. I'm an AI researcher. I love programming but I prefer training models to write code for me.. I am Staff Research Scientist at ByteDance Seed working on foundational model training. Prior to that I’m a Senior Applied Scientist at Amazon, specializing in foundational model pre-training, post-training, and reinforcement learning for complex reasoning tasks. My expertise spans the full stack of large language model (LLM) development, including data curation, pretraining, supervised fine-tuning (SFT), and reinforcement learning with human feedback (RLHF). I have experience training both text and code models. Most recently, I’ve been focusing on deep RL for math, code generation tasks.\nOpinions are my own and I do not speak for my employer or my team. On this webpage, I'd like to share my study and my paper reading. Feel free to reach out to me if you have any comments/suggestions\nIn my spare time, I like hiking a lot. I'm also very much into reading books of history, biography etc. Drop me a line if you want to chat more! All my publications can be found on google scholar\nProfessional Services Reviewer for ACL ARR 2024, EMNLP 2025, ICLR 2025 Reviewer for NeurIPS, ICLR 2023 Reviewer for AMLC 2020, 2021 Reviewer for ICLR 2022 Reviewer for AAAI 2021 I served as the Amazon Research Award reviewer and was an AC for AMLC conference at Amazon.\n","wordCount":"238","inLanguage":"en-us","datePublished":"2021-11-06T14:57:28+08:00","dateModified":"2021-11-06T14:57:28+08:00","author":{"@type":"Person","name":"Jun"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://rich-junwang.github.io/en-us/about/"},"publisher":{"@type":"Organization","name":"Jun's Blog","logo":{"@type":"ImageObject","url":"https://rich-junwang.github.io/img/Q.gif"}}}</script></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://rich-junwang.github.io/en-us/ accesskey=h title="Jun's Blog (Alt + H)"><img src=https://rich-junwang.github.io/img/Q.gif alt=logo aria-label=logo height=35>Jun's Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)">
<svg id="moon" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li></ul></div></div><ul id=menu><li><a href=https://rich-junwang.github.io/en-us/ title="🏠 Home"><span>🏠 Home</span></a></li><li><a href=https://rich-junwang.github.io/en-us/about title="🙋🏻‍♂️ About"><span class=active>🙋🏻‍♂️ About</span></a></li><li><a href=https://rich-junwang.github.io/en-us/posts title="📚 Posts"><span>📚 Posts</span></a></li><li><a href=https://rich-junwang.github.io/en-us/tags title="🧩 Tags"><span>🧩 Tags</span></a></li><li><a href=https://rich-junwang.github.io/en-us/archives/ title="⏱️ Archives"><span>⏱️ Archives</span></a></li><li><a href=https://rich-junwang.github.io/en-us/search title="🔍 Search (Alt + /)" accesskey=/><span>🔍 Search</span></a></li></ul></nav></header><main class="main page"><style>i[id*=post_meta_style]{display:flex;align-items:center;margin:0 0 10px}</style><article class=post-single><div id=single-content><header class=post-header><h1 class=post-title>🙋🏻‍♂️About</h1></header><div class=post-content><p style=font-size:25px>About Me</p><style>.wrap{float:right;margin:5px}#mypic{width:200px;border-radius:200%;align:left;padding:20px;border:2px solid #d3d3d3}</style><div class=wrap><img class="img-fluid z-depth-1 rounded" id=mypic src=/img/junwang.jpeg></div><p>Hi there, this is Jun Wang. Welcome to my website. I'm an AI researcher. I love programming but I prefer training models to write code for me..<p>I am Staff Research Scientist at ByteDance Seed working on foundational model training. Prior to that I&rsquo;m a Senior Applied Scientist at Amazon, specializing in foundational model pre-training, post-training, and reinforcement learning for complex reasoning tasks. My expertise spans the full stack of large language model (LLM) development, including data curation, pretraining, supervised fine-tuning (SFT), and reinforcement learning with human feedback (RLHF). I have experience training both text and code models. Most recently, I&rsquo;ve been focusing on deep RL for math, code generation tasks.</p></p><p>Opinions are my own and I do not speak for my employer or my team. On this webpage, I'd like to share my study and my
paper reading. Feel free to reach out to me if you have any comments/suggestions</p><p>In my spare time, I like hiking a lot. I'm also very much into reading books of history, biography etc. Drop me a line if
you want to chat more!</p><p>All my publications can be found on <a href="https://scholar.google.com/citations?user=ct92MO4AAAAJ&amp;hl=en">google scholar</a></p><p style=font-size:25px>Professional Services<ul><li>Reviewer for ACL ARR 2024, EMNLP 2025, ICLR 2025</li><li>Reviewer for NeurIPS, ICLR 2023</li><li>Reviewer for AMLC 2020, 2021</li><li>Reviewer for ICLR 2022</li><li>Reviewer for AAAI 2021</li></ul><p>I served as the Amazon Research Award reviewer and was an AC for AMLC conference at Amazon.</p></div><footer class=post-footer></footer></div><style>.comments_details summary::marker{font-size:20px;content:'👉Comment';color:var(--content)}.comments_details[open] summary::marker{font-size:20px;content:'👇Collapse';color:var(--content)}</style><div><details class=comments_details><summary style="cursor:pointer;margin:50px 0 20px;width:130px"><span style=font-size:20px;color:var(--content)>...</span></summary><div id=tcomment></div></details><script src=https://cdn.staticfile.org/twikoo/1.5.8/twikoo.all.min.js></script><script>twikoo.init({envId:null,el:"#tcomment",lang:"en-us",region:null,path:window.TWIKOO_MAGIC_PATH||window.location.pathname})</script></div></article></main><footer class=footer><span>Copyright
&copy;
2020-2025
<a href=https://rich-junwang.github.io/en-us/ style=color:#939393>Jun's Blog</a>
All Rights Reserved
</span><a href=https://beian.miit.gov.cn/ target=_blank style=color:#939393></a>&nbsp;
<span id=busuanzi_container><span class="fa fa-user"></span> <span id=busuanzi_value_site_uv></span>
<span class="fa fa-eye"></span> <span id=busuanzi_value_site_pv></span></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><span class=topInner><svg class="topSvg" viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
<span id=read_progress></span>
</span></a><script>document.addEventListener("scroll",function(){const t=document.getElementById("read_progress"),n=document.documentElement.scrollHeight,s=document.documentElement.clientHeight,o=document.documentElement.scrollTop||document.body.scrollTop;t.innerText=((o/(n-s)).toFixed(2)*100).toFixed(0)})</script><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>let mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>200||document.documentElement.scrollTop>200?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{(function(){document.cookie="change-themes="+escape("false")})(),document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.body.addEventListener("copy",function(e){if(window.getSelection().toString()&&window.getSelection().toString().length>50){let t=e.clipboardData||window.clipboardData;if(t){e.preventDefault();let n=window.getSelection().toString()+`\r

————————————————\r
版权声明：本文为「Jun's Blog」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。\r
原文链接：`+location.href,s=window.getSelection().toString()+`\r

————————————————\r
版权声明：本文为「Jun's Blog」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。\r
原文链接：`+location.href;t.setData("text/html",n),t.setData("text/plain",s)}}})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const s=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerText="copy";function i(){t.innerText="copied!",setTimeout(()=>{t.innerText="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){let t=e.textContent+`\r
————————————————\r
版权声明：本文为「Jun's Blog」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。\r
原文链接：`+location.href;navigator.clipboard.writeText(t),i();return}const n=document.createRange();n.selectNodeContents(e);const s=window.getSelection();s.removeAllRanges(),s.addRange(n);try{document.execCommand("copy"),i()}catch{}s.removeRange(n)});let l=e.className.replaceAll("language-",""),n=document.createElement("div"),a=document.createElement("div"),r=document.createElement("div"),c=document.createElement("div"),o=document.createElement("div");o.innerText=l,n.setAttribute("class","mac-tool"),a.setAttribute("class","mac bb1"),r.setAttribute("class","mac bb2"),c.setAttribute("class","mac bb3"),o.setAttribute("class","language-type"),n.appendChild(a),n.appendChild(r),n.appendChild(c),n.appendChild(o),s.classList.contains("highlight")?(s.appendChild(t),s.appendChild(n)):s.parentNode.firstChild==s||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?(e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t),s.appendChild(n)):(e.parentNode.appendChild(t),s.appendChild(n)))})</script></body></html>
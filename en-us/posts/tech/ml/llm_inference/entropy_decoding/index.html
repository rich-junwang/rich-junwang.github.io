<!doctype html><html lang=en-us dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Entropy Collapsing in RL Training | Jun's Blog</title><meta name=keywords content><meta name=description content="Decoding"><meta name=author content="Jun"><link rel=canonical href=https://rich-junwang.github.io/en-us/posts/tech/ml/llm_inference/entropy_decoding/><link crossorigin=anonymous href=/assets/css/stylesheet.css rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.js onload=hljs.initHighlightingOnLoad()></script><link rel=icon href=https://rich-junwang.github.io/img/Q.gif><link rel=icon type=image/png sizes=16x16 href=https://rich-junwang.github.io/img/Q.gif><link rel=icon type=image/png sizes=32x32 href=https://rich-junwang.github.io/img/Q.gif><link rel=apple-touch-icon href=https://rich-junwang.github.io/img/Q.gif><link rel=mask-icon href=https://rich-junwang.github.io/img/Q.gif><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en-us href=https://rich-junwang.github.io/en-us/posts/tech/ml/llm_inference/entropy_decoding/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script defer src=https://unpkg.com/mermaid@8.8.1/dist/mermaid.min.js></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/font-awesome@4.7.0/css/font-awesome.min.css><script src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script><script src=https://cdn.jsdelivr.net/npm/jquery@3.6.3/dist/jquery.min.js></script><script>var _hmt=_hmt||[];(function(){var e,t=document.createElement("script");t.src="",e=document.getElementsByTagName("script")[0],e.parentNode.insertBefore(t,e)})()</script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css integrity=sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js integrity=sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js integrity=sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa crossorigin=anonymous onload='renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"\\[",right:"\\]",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1}]})'></script><meta property="og:title" content="Entropy Collapsing in RL Training"><meta property="og:description" content="Decoding"><meta property="og:type" content="article"><meta property="og:url" content="https://rich-junwang.github.io/en-us/posts/tech/ml/llm_inference/entropy_decoding/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-01-05T00:18:23+08:00"><meta property="article:modified_time" content="2025-01-05T00:18:23+08:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Entropy Collapsing in RL Training"><meta name=twitter:description content="Decoding"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"ğŸ“šArticles","item":"https://rich-junwang.github.io/en-us/posts/"},{"@type":"ListItem","position":2,"name":"ğŸ‘¨ğŸ»â€ğŸ’» Tech","item":"https://rich-junwang.github.io/en-us/posts/tech/"},{"@type":"ListItem","position":3,"name":"Entropy Collapsing in RL Training","item":"https://rich-junwang.github.io/en-us/posts/tech/ml/llm_inference/entropy_decoding/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Entropy Collapsing in RL Training","name":"Entropy Collapsing in RL Training","description":"Decoding","keywords":[""],"articleBody":"Entropy Collapsing Itâ€™s common to see entropy collapsing phenomenon in GRPO based RL model training: the entropy of token generation of policy model decreases dramatically as training progresses.\nBefore diving deep into the topic, letâ€™s first take a look at the entropy and varentropy of LLM generation process. Entropy measures how confident the model is when generating a specific token. Itâ€™s calculated at each generation step. Low entropy indicates that the model is certain about next token, i.e. the probabilities are concentrated on a few tokens.\n$$ H(X) = -\\sum_{x \\in \\mathcal{X}} P(x) \\log P(x) $$\nAnother concept is varentropy. Variance of (âˆ’ log p(X)) of the discrete random variable X is called the varentropy. Varentropy is a measure of how the uncertainty varies across different tokens in generation. Mathematically the varentropy is defined as\n$$ \\begin{aligned} V(X) \u0026= \\text{Var}(-\\log P(X)) \\\\ \u0026= \\sum_{x \\in \\mathcal{X}} P(x) \\left(-\\log_2 P(x) - H(X)\\right)^2 \\\\ \u0026= \\mathbb{E}[(-\\log P(X))^2] - (H(X))^2 \\end{aligned} $$\nLow varentropy means the modelâ€™s uncertainty is consistent across tokens whereas the high varentropy means that modelâ€™s uncertainty varies significantly in generated tokens.\nThe computation of entropy and varentropy in python is implemented below.\nimport torch from typing import Optional, Tuple def calculate_entropy_and_varentropy( probs: torch.Tensor, log_probs: Optional[torch.Tensor] = None, eps: float = 1e-12 ) -\u003e Tuple[torch.Tensor, torch.Tensor]: \"\"\" Compute entropy and varentropy (variance of surprise) of a discrete probability distribution. Args: probs (torch.Tensor): Probability tensor of shape (..., num_classes), where the last dim sums to 1. log_probs (Optional[torch.Tensor]): Optional precomputed log2 probabilities (same shape as probs). eps (float): Small constant for numerical stability to avoid log(0). Returns: Tuple[torch.Tensor, torch.Tensor]: A tuple (entropy, varentropy), each of shape (...) matching the batch dimensions. \"\"\" # Ensure numerical stability safe_probs = torch.clamp(probs, min=eps) # Compute log2 probabilities if not provided if log_probs is None: log_probs = torch.log2(safe_probs) # Compute entropy: H(X) = -Î£ p(x) log2 p(x) entropy = -torch.sum(safe_probs * log_probs, dim=-1) # Compute varentropy: V(X) = Î£ p(x) (âˆ’log2 p(x) âˆ’ H(X))Â² surprise = -log_probs mean_surprise = entropy.unsqueeze(-1) # shape (..., 1) for broadcasting squared_deviation = (surprise - mean_surprise) ** 2 varentropy = torch.sum(safe_probs * squared_deviation, dim=-1) return entropy, varentropy As is shown in ref 4, LLMs cannot reason if we only consider the greedy decoding path. In other words, reasoning is achieved through a less certain decoding path. In the DAPO paper, the solution is to increase the clip upper bound of importance sampling ratio. Through adjusting the $\\epsilon$, we effectively increase the possibility of choosing low-probability tokens.\nAs we figure out that the approach to prevent entropy collapsing is to increase the entropy of generated tokens, we can implement entropy based sampling approach in RL training. Ref 1 has provide a good base solution for this kind of entropy based sampling.\nReferences https://github.com/xjdr-alt/entropix DAPO: An Open-Source LLM Reinforcement Learning System at Scale https://southbridge-research.notion.site/Entropixplained-11e5fec70db18022b083d7d7b0e93505 Chain-of-Thought Reasoning without Prompting ","wordCount":"494","inLanguage":"en-us","datePublished":"2025-01-05T00:18:23+08:00","dateModified":"2025-01-05T00:18:23+08:00","author":[{"@type":"Person","name":"Jun"}],"mainEntityOfPage":{"@type":"WebPage","@id":"https://rich-junwang.github.io/en-us/posts/tech/ml/llm_inference/entropy_decoding/"},"publisher":{"@type":"Organization","name":"Jun's Blog","logo":{"@type":"ImageObject","url":"https://rich-junwang.github.io/img/Q.gif"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://rich-junwang.github.io/en-us/ accesskey=h title="Jun's Blog (Alt + H)"><img src=https://rich-junwang.github.io/img/Q.gif alt=logo aria-label=logo height=35>Jun's Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)">
<svg id="moon" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li></ul></div></div><ul id=menu><li><a href=https://rich-junwang.github.io/en-us/ title="ğŸ  Home"><span>ğŸ  Home</span></a></li><li><a href=https://rich-junwang.github.io/en-us/about title="ğŸ™‹ğŸ»â€â™‚ï¸ About"><span>ğŸ™‹ğŸ»â€â™‚ï¸ About</span></a></li><li><a href=https://rich-junwang.github.io/en-us/posts title="ğŸ“š Posts"><span>ğŸ“š Posts</span></a></li><li><a href=https://rich-junwang.github.io/en-us/tags title="ğŸ§© Tags"><span>ğŸ§© Tags</span></a></li><li><a href=https://rich-junwang.github.io/en-us/archives/ title="â±ï¸ Archives"><span>â±ï¸ Archives</span></a></li><li><a href=https://rich-junwang.github.io/en-us/search title="ğŸ” Search (Alt + /)" accesskey=/><span>ğŸ” Search</span></a></li></ul></nav></header><main class="main page"><style>i[id*=post_meta_style]{display:flex;align-items:center;margin:0 0 10px}</style><article class=post-single><div id=single-content><header class=post-header><div class=breadcrumbs><a href=https://rich-junwang.github.io/en-us/>ğŸ  Home</a>&nbsp;Â»&nbsp;<a href=https://rich-junwang.github.io/en-us/posts/>ğŸ“šArticles</a>&nbsp;Â»&nbsp;<a href=https://rich-junwang.github.io/en-us/posts/tech/>ğŸ‘¨ğŸ»â€ğŸ’» Tech</a></div><h1 class=post-title>Entropy Collapsing in RL Training</h1><div class=post-description>Decoding</div><div class=post-meta><style>i[id*=post_meta_style]{display:flex;align-items:center;margin:0 0 10px}.parent-post-meta{display:flex;flex-wrap:wrap;opacity:.8}</style><span class=parent-post-meta><span id=post_meta_style_1><span class="fa fa-calendar-check-o"></span>
<span>2025-01-05
&nbsp;&nbsp;
</span></span><span id=post_meta_style_3><span class="fa fa-file-word-o"></span>
<span>494 words
&nbsp;&nbsp;
</span></span><span id=post_meta_style_4><span class="fa fa-clock-o"></span>
<span>1 min
&nbsp;&nbsp;
</span></span><span id=post_meta_style_5><span class="fa fa-user-o"></span>
<span>Jun
&nbsp;&nbsp;
</span></span><span id=post_meta_style_6><span class="fa fa-tags" style=opacity:.8></span>
<span><span class=post-tags-meta><a href=https://rich-junwang.github.io/en-us/tags/ml/ style="color:var(--secondary) !important">ML</a>
</span></span></span></span><span style=opacity:.8><span id=post_meta_style_7>&nbsp;&nbsp;
<span class="fa fa-eye"></span>
<span><span id=busuanzi_container_page_pv><span id=busuanzi_value_page_pv></span></span>
&nbsp;&nbsp;
</span></span><span id=post_meta_style_8><span class="fa fa-commenting-o"></span>
<span><script src=https://cdn.staticfile.org/twikoo/1.5.8/twikoo.all.min.js></script><script>let url=document.documentURI,dnsUrl="https://rich-junwang.github.io/",urlSplit=url.split(dnsUrl),finalUrl=urlSplit[1];finalUrl[0]!=="/"&&(finalUrl="/"+finalUrl),twikoo.getCommentsCount({envId:null,region:null,urls:[finalUrl],includeReply:!1}).then(function(e){let t=e[0].count;const n=document.getElementById("comment_count");n.innerText=t}).catch(function(e){console.error(e)})</script><span id=comment_count></span></span></span></span></div></header><aside id=toc-container class="toc-container wide"><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#entropy-collapsing aria-label="Entropy Collapsing">Entropy Collapsing</a><ul><li><a href=#references aria-label=References>References</a></li></ul></li></ul></div></details></div></aside><script>let activeElement,elements;window.addEventListener("DOMContentLoaded",function(){checkTocPosition(),elements=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]"),activeElement=elements[0];const t=encodeURI(activeElement.getAttribute("id")).toLowerCase();document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active")},!1),window.addEventListener("resize",function(){checkTocPosition()},!1),window.addEventListener("scroll",()=>{elements&&(activeElement=Array.from(elements).find(e=>{if(getOffsetTop(e)-window.pageYOffset>0&&getOffsetTop(e)-window.pageYOffset<window.innerHeight/2)return e})||activeElement,elements.forEach(e=>{const t=encodeURI(e.getAttribute("id")).toLowerCase();e===activeElement?document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active"):document.querySelector(`.inner ul li a[href="#${t}"]`).classList.remove("active")}))},!1);const main=parseInt(getComputedStyle(document.body).getPropertyValue("--article-width"),10),toc=parseInt(getComputedStyle(document.body).getPropertyValue("--toc-width"),10),gap=parseInt(getComputedStyle(document.body).getPropertyValue("--gap"),10);function checkTocPosition(){const e=document.body.scrollWidth;e-main-toc*2-gap*4>0?document.getElementById("toc-container").classList.add("wide"):document.getElementById("toc-container").classList.remove("wide")}function getOffsetTop(e){if(!e.getClientRects().length)return 0;let t=e.getBoundingClientRect(),n=e.ownerDocument.defaultView;return t.top+n.pageYOffset}</script><div class=post-content><h2 id=entropy-collapsing>Entropy Collapsing<a hidden class=anchor aria-hidden=true href=#entropy-collapsing>#</a></h2><p>It&rsquo;s common to see entropy collapsing phenomenon in GRPO based RL model training: the entropy of token generation of policy model decreases dramatically as training progresses.</p><p>Before diving deep into the topic, let&rsquo;s first take a look at the entropy and varentropy of LLM generation process. Entropy measures how confident the model is when generating a specific token. It&rsquo;s calculated at each generation step. Low entropy indicates that the model is certain about next token, i.e. the probabilities are concentrated on a few tokens.</p><p>$$
H(X) = -\sum_{x \in \mathcal{X}} P(x) \log P(x)
$$</p><p>Another concept is varentropy. Variance of (âˆ’ log p(X)) of the discrete random variable X is called
the varentropy. Varentropy is a measure of how the uncertainty varies across different tokens in generation. Mathematically the varentropy is defined as</p><p>$$
\begin{aligned}
V(X) &= \text{Var}(-\log P(X)) \\
&= \sum_{x \in \mathcal{X}} P(x) \left(-\log_2 P(x) - H(X)\right)^2 \\
&= \mathbb{E}[(-\log P(X))^2] - (H(X))^2
\end{aligned}
$$</p><p>Low varentropy means the modelâ€™s uncertainty is consistent across tokens whereas the high varentropy means that model&rsquo;s uncertainty varies significantly in generated tokens.</p><p>The computation of entropy and varentropy in python is implemented below.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> torch
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> typing <span style=color:#f92672>import</span> Optional, Tuple
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>calculate_entropy_and_varentropy</span>(
</span></span><span style=display:flex><span>    probs: torch<span style=color:#f92672>.</span>Tensor,
</span></span><span style=display:flex><span>    log_probs: Optional[torch<span style=color:#f92672>.</span>Tensor] <span style=color:#f92672>=</span> <span style=color:#66d9ef>None</span>,
</span></span><span style=display:flex><span>    eps: float <span style=color:#f92672>=</span> <span style=color:#ae81ff>1e-12</span>
</span></span><span style=display:flex><span>) <span style=color:#f92672>-&gt;</span> Tuple[torch<span style=color:#f92672>.</span>Tensor, torch<span style=color:#f92672>.</span>Tensor]:
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;&#34;&#34;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    Compute entropy and varentropy (variance of surprise) of a discrete probability distribution.
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    Args:
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        probs (torch.Tensor): Probability tensor of shape (..., num_classes), where the last dim sums to 1.
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        log_probs (Optional[torch.Tensor]): Optional precomputed log2 probabilities (same shape as probs).
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        eps (float): Small constant for numerical stability to avoid log(0).
</span></span></span><span style=display:flex><span><span style=color:#e6db74>
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    Returns:
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        Tuple[torch.Tensor, torch.Tensor]: A tuple (entropy, varentropy), each of shape (...) matching the batch dimensions.
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    &#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># Ensure numerical stability</span>
</span></span><span style=display:flex><span>    safe_probs <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>clamp(probs, min<span style=color:#f92672>=</span>eps)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># Compute log2 probabilities if not provided</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> log_probs <span style=color:#f92672>is</span> <span style=color:#66d9ef>None</span>:
</span></span><span style=display:flex><span>        log_probs <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>log2(safe_probs)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># Compute entropy: H(X) = -Î£ p(x) log2 p(x)</span>
</span></span><span style=display:flex><span>    entropy <span style=color:#f92672>=</span> <span style=color:#f92672>-</span>torch<span style=color:#f92672>.</span>sum(safe_probs <span style=color:#f92672>*</span> log_probs, dim<span style=color:#f92672>=-</span><span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># Compute varentropy: V(X) = Î£ p(x) (âˆ’log2 p(x) âˆ’ H(X))Â²</span>
</span></span><span style=display:flex><span>    surprise <span style=color:#f92672>=</span> <span style=color:#f92672>-</span>log_probs
</span></span><span style=display:flex><span>    mean_surprise <span style=color:#f92672>=</span> entropy<span style=color:#f92672>.</span>unsqueeze(<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>)  <span style=color:#75715e># shape (..., 1) for broadcasting</span>
</span></span><span style=display:flex><span>    squared_deviation <span style=color:#f92672>=</span> (surprise <span style=color:#f92672>-</span> mean_surprise) <span style=color:#f92672>**</span> <span style=color:#ae81ff>2</span>
</span></span><span style=display:flex><span>    varentropy <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>sum(safe_probs <span style=color:#f92672>*</span> squared_deviation, dim<span style=color:#f92672>=-</span><span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> entropy, varentropy
</span></span></code></pre></div><p>As is shown in ref 4, LLMs cannot reason if we only consider the greedy decoding path. In other words, reasoning is achieved through a less certain decoding path. In the DAPO paper, the solution is to increase the clip upper bound of importance sampling ratio. Through adjusting the $\epsilon$, we effectively increase the possibility of choosing low-probability tokens.</p><p>As we figure out that the approach to prevent entropy collapsing is to increase the entropy of generated tokens, we can implement entropy based sampling approach in RL training. Ref 1 has provide a good base solution for this kind of entropy based sampling.</p><h3 id=references>References<a hidden class=anchor aria-hidden=true href=#references>#</a></h3><ol><li><a href=https://github.com/xjdr-alt/entropix>https://github.com/xjdr-alt/entropix</a></li><li>DAPO: An Open-Source LLM Reinforcement Learning System at Scale</li><li><a href=https://southbridge-research.notion.site/Entropixplained-11e5fec70db18022b083d7d7b0e93505>https://southbridge-research.notion.site/Entropixplained-11e5fec70db18022b083d7d7b0e93505</a></li><li>Chain-of-Thought Reasoning without Prompting</li></ol></div><footer class=post-footer><nav class=paginav><a class=prev href=https://rich-junwang.github.io/en-us/posts/tech/ml/model_distillation/><span class=title>Â«</span><br><span>Distillation</span>
</a><a class=next href=https://rich-junwang.github.io/en-us/posts/tech/ml/llm_inference/vllm/><span class=title>Â»</span><br><span>vLLM</span></a></nav></footer></div><style>.comments_details summary::marker{font-size:20px;content:'ğŸ‘‰Comment';color:var(--content)}.comments_details[open] summary::marker{font-size:20px;content:'ğŸ‘‡Collapse';color:var(--content)}</style><div><details class=comments_details><summary style="cursor:pointer;margin:50px 0 20px;width:130px"><span style=font-size:20px;color:var(--content)>...</span></summary><div id=tcomment></div></details><script src=https://cdn.staticfile.org/twikoo/1.5.8/twikoo.all.min.js></script><script>twikoo.init({envId:null,el:"#tcomment",lang:"en-us",region:null,path:window.TWIKOO_MAGIC_PATH||window.location.pathname})</script></div></article></main><footer class=footer><span>Copyright
&copy;
2020-2025
<a href=https://rich-junwang.github.io/en-us/ style=color:#939393>Jun's Blog</a>
All Rights Reserved
</span><a href=https://beian.miit.gov.cn/ target=_blank style=color:#939393></a>&nbsp;
<span id=busuanzi_container><span class="fa fa-user"></span> <span id=busuanzi_value_site_uv></span>
<span class="fa fa-eye"></span> <span id=busuanzi_value_site_pv></span></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><span class=topInner><svg class="topSvg" viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
<span id=read_progress></span>
</span></a><script>document.addEventListener("scroll",function(){const t=document.getElementById("read_progress"),n=document.documentElement.scrollHeight,s=document.documentElement.clientHeight,o=document.documentElement.scrollTop||document.body.scrollTop;t.innerText=((o/(n-s)).toFixed(2)*100).toFixed(0)})</script><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>let mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>200||document.documentElement.scrollTop>200?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{(function(){document.cookie="change-themes="+escape("false")})(),document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.body.addEventListener("copy",function(e){if(window.getSelection().toString()&&window.getSelection().toString().length>50){let t=e.clipboardData||window.clipboardData;if(t){e.preventDefault();let n=window.getSelection().toString()+`\r

â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\r
ç‰ˆæƒå£°æ˜ï¼šæœ¬æ–‡ä¸ºã€ŒJun's Blogã€çš„åŸåˆ›æ–‡ç« ï¼Œéµå¾ªCC 4.0 BY-SAç‰ˆæƒåè®®ï¼Œè½¬è½½è¯·é™„ä¸ŠåŸæ–‡å‡ºå¤„é“¾æ¥åŠæœ¬å£°æ˜ã€‚\r
åŸæ–‡é“¾æ¥ï¼š`+location.href,s=window.getSelection().toString()+`\r

â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\r
ç‰ˆæƒå£°æ˜ï¼šæœ¬æ–‡ä¸ºã€ŒJun's Blogã€çš„åŸåˆ›æ–‡ç« ï¼Œéµå¾ªCC 4.0 BY-SAç‰ˆæƒåè®®ï¼Œè½¬è½½è¯·é™„ä¸ŠåŸæ–‡å‡ºå¤„é“¾æ¥åŠæœ¬å£°æ˜ã€‚\r
åŸæ–‡é“¾æ¥ï¼š`+location.href;t.setData("text/html",n),t.setData("text/plain",s)}}})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const s=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerText="copy";function i(){t.innerText="copied!",setTimeout(()=>{t.innerText="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){let t=e.textContent+`\r
â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\r
ç‰ˆæƒå£°æ˜ï¼šæœ¬æ–‡ä¸ºã€ŒJun's Blogã€çš„åŸåˆ›æ–‡ç« ï¼Œéµå¾ªCC 4.0 BY-SAç‰ˆæƒåè®®ï¼Œè½¬è½½è¯·é™„ä¸ŠåŸæ–‡å‡ºå¤„é“¾æ¥åŠæœ¬å£°æ˜ã€‚\r
åŸæ–‡é“¾æ¥ï¼š`+location.href;navigator.clipboard.writeText(t),i();return}const n=document.createRange();n.selectNodeContents(e);const s=window.getSelection();s.removeAllRanges(),s.addRange(n);try{document.execCommand("copy"),i()}catch{}s.removeRange(n)});let l=e.className.replaceAll("language-",""),n=document.createElement("div"),a=document.createElement("div"),r=document.createElement("div"),c=document.createElement("div"),o=document.createElement("div");o.innerText=l,n.setAttribute("class","mac-tool"),a.setAttribute("class","mac bb1"),r.setAttribute("class","mac bb2"),c.setAttribute("class","mac bb3"),o.setAttribute("class","language-type"),n.appendChild(a),n.appendChild(r),n.appendChild(c),n.appendChild(o),s.classList.contains("highlight")?(s.appendChild(t),s.appendChild(n)):s.parentNode.firstChild==s||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?(e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t),s.appendChild(n)):(e.parentNode.appendChild(t),s.appendChild(n)))})</script></body></html>
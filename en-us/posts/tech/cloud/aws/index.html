<!doctype html><html lang=en-us dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>A Walk in the Cloud | Jun's Blog</title><meta name=keywords content><meta name=description content="AWS"><meta name=author content="Jun"><link rel=canonical href=https://rich-junwang.github.io/en-us/posts/tech/cloud/aws/><link crossorigin=anonymous href=/assets/css/stylesheet.css rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.js onload=hljs.initHighlightingOnLoad()></script><link rel=icon href=https://rich-junwang.github.io/img/Q.gif><link rel=icon type=image/png sizes=16x16 href=https://rich-junwang.github.io/img/Q.gif><link rel=icon type=image/png sizes=32x32 href=https://rich-junwang.github.io/img/Q.gif><link rel=apple-touch-icon href=https://rich-junwang.github.io/img/Q.gif><link rel=mask-icon href=https://rich-junwang.github.io/img/Q.gif><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en-us href=https://rich-junwang.github.io/en-us/posts/tech/cloud/aws/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script defer src=https://unpkg.com/mermaid@8.8.1/dist/mermaid.min.js></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/font-awesome@4.7.0/css/font-awesome.min.css><script src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script><script src=https://cdn.jsdelivr.net/npm/jquery@3.6.3/dist/jquery.min.js></script><script>var _hmt=_hmt||[];(function(){var e,t=document.createElement("script");t.src="",e=document.getElementsByTagName("script")[0],e.parentNode.insertBefore(t,e)})()</script><meta property="og:title" content="A Walk in the Cloud"><meta property="og:description" content="AWS"><meta property="og:type" content="article"><meta property="og:url" content="https://rich-junwang.github.io/en-us/posts/tech/cloud/aws/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-05-05T00:17:58+08:00"><meta property="article:modified_time" content="2022-05-05T00:17:58+08:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="A Walk in the Cloud"><meta name=twitter:description content="AWS"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"ğŸ“šArticles","item":"https://rich-junwang.github.io/en-us/posts/"},{"@type":"ListItem","position":2,"name":"ğŸ‘¨ğŸ»â€ğŸ’» Tech","item":"https://rich-junwang.github.io/en-us/posts/tech/"},{"@type":"ListItem","position":3,"name":"A Walk in the Cloud","item":"https://rich-junwang.github.io/en-us/posts/tech/cloud/aws/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"A Walk in the Cloud","name":"A Walk in the Cloud","description":"AWS","keywords":[""],"articleBody":"In this doc, I keep record of some commonly used aws related commands for my quick reference. Iâ€™ll be very glad if this could be somewhat helpful to you.\nECR ECR login\nFor aws-cli 2.7 or above version, use the command below:\n# check all images aws ecr describe-repositories # login the docker aws ecr get-login-password --region | docker login --username AWS --password-stdin .dkr.ecr..amazonaws.com # we can get the aws account id using the following command aws ecr get-login-password --region | docker login --username AWS --password-stdin \"$(aws sts get-caller-identity --query Account --output text).dkr.ecr..amazonaws.com\" # pull the image docker pull # If we pushed the image using sudo, then pull also add sudo sudo docker pull Sometimes we need one image in one region, but itâ€™s pushed to another region. We can do the dollowing steps to push the image to target region.\n# login to the region where the image current is. Here assume it's in us-east-1 REGION=us-east-1 ; aws ecr get-login-password --region ${REGION} | docker login --username AWS --password-stdin .dkr.ecr.${REGION}.amazonaws.com # Then pull the image from ECR docker pull image_name # Find out the image id docker image ls | grep image_name | cut -f3 # tag docker tag image_id new_image_tag_with_new_region # login to the new region REGION=us-west-2 ; aws ecr get-login-password --region ${REGION} | docker login --username AWS --password-stdin .dkr.ecr.${REGION}.amazonaws.com # push docker push new_image_tag_with_new_region GitLab and Github Gitlab changes its authentication methods and the way it works is almost identical to Github. The easiest way to use it is through personal token.\n# For gitlab usage # clone a repo using personal token git clone https://oauth2:personal_token@gitlab.com/username/project.git git remote set-url origin https://oauth2:personal_token@gitlab.com/username/project.git git push https://personal_token@gitlab.com/username/project.git ## For github usage git clone https://username:personal_token@github.com/username/project.git . git remote set-url origin https://username:personal_token@github.com/username/project.git git push https://personal_token@github.com/username/project.git Another simpler way to clone personal repo on a new machine (1) Add ssh public key into github/gitlab webpage. settings -\u003e ssh and GPG keys -\u003e add ssh key. (2) To clone a repo, use ssh link. git@github.com:xxx\nWe can also use https to clone a repo, but need to add personal access token from github.\nCommon AWS CLI To get the current region,\naws configure get region # if using the profile aws configure get region --profile $PROFILE_NAME # aws sync with exclude aws s3 sync s3://my-first-bucket s3://my-second-bucket --exclude 'datasets/*' # get the identity aws sts get-caller-identity # export credentials export $(ada credentials print --account xxx --role myrole --provider=myprovider --profile my_profile --format env | xargs -L 1) CloudWatch To use cloudwatch insight, we can use the following query\nfields @timestamp, @message, @logStream | filter @logStream like /xxxxx/ | sort @timestamp desc | limit 10000 VPC and Security Group Security group controls how we login the instance (like through ssh etc) VPC determines what kind of resource we can visit from the instance. For instance if we are able to access specific EFS and FSx. Private VPC subnet will require a bastion to connect to instance.\nkubernetes architecture, image from [1] An Internet Gateway is a logical connection between a VPC and the Internet. If there is no Internet Gateway, then the VPC has no direct access to the Internet. (However, Internet access might be provided via a Transit Gateway, which itself would need an Internet Gateway.)\nThink of the Internet Gateway as the wire that you use to connect your home router to the Internet. Pull out that wire and your home network wonâ€™t be connected to the Internet.\nA subnet is a â€˜public subnetâ€™ if it has a Route Table that references an Internet Gateway.\nA NAT Gateway receives traffic from a VPC, forwards it to the Internet and then returns the response that was received. It must live in a public subnet because it needs to communicate with the Internet (and therefore needs a route to the Internet Gateway).\nResources in a private subnet (which, by definition, cannot route to the Internet Gateway) will have their Internet-bound requests sent to the NAT Gateway (due to a Route Table configuration). The NAT Gateway will then forward that request to the Internet and return the response that was received from the Internet.\nNAT Gateways exist because organizations want the additional security offered by private subnets, which guarantee that there is no inbound access from the Internet. Similar security can be provided with a Security Group, so private subnets arenâ€™t actually required. However, people who are familiar with traditional (non-cloud) networking are familiar with the concept of public and private subnets, so they want to replicate that architecture in the cloud. Physical network routers only apply rules at the boundary of subnets, whereas Security Groups can be applied individually to each Resource. Itâ€™s a bit like giving each resource its own router.\nYou are right that all of the above is implemented as a virtual network. There is no physical device called an Internet Gateway or a NAT Gateway. Much of it is logical routing, although the NAT Gateway does involve launching infrastructure behind-the-scenes (probably on the same infrastructure that runs EC2 instances). The NAT Gateway only connects to one VPC â€“ it is not a â€˜shared serviceâ€™ like Amazon S3, which is available to many AWS users simultaneously.\nYou also mention performing work â€˜manuallyâ€™. An entire VPC (including subnets, route tables, Internet Gateway, NAT Gateway, Security Groups) can be deployed automatically using an AWS CloudFormation template, or via the VPC Wizard in the VPC management console.\nEFS # install efs-utils, depends on platform, it could be different. # Then mkdir $HOME/efs sudo mount -t efs efs_id $HOME/efs EKS # create an eks without node group eksctl create cluster --region us-east-1 --without-nodegroup --vpc-public-subnets ${subnets} # dry run eksctl create cluster -f ./eks.yaml --dry-run When use cloudformation to create eks node group, the hardware could fail. We can use the following command to check the failure. The first failure in the stack (the resource provision is in a certain order) is usually what weâ€™re looking for.\naws cloudformation describe-stack-events --stack-name my-cluster-stack-name To delete a failed stack\naws cloudformation delete-stack --stack-name my-cluster-stack-name FSx for Lustre Lustre (linux + cluster) is a high performance file system. FSx for lustre is an aws managed service to launch and run for lustre file system.\nFSx and S3 s3 is long-term durable storage. FSx for lustre is used when processing data. Usually FSx is used as a high performance file system linked into s3 bucket.\nStore your data on s3 Create an FSx file system and link it to your s3 bucket At any time, use a lustre command to write changes back to s3 Delete FSx file system when youâ€™re done processing ","wordCount":"1104","inLanguage":"en-us","datePublished":"2022-05-05T00:17:58+08:00","dateModified":"2022-05-05T00:17:58+08:00","author":[{"@type":"Person","name":"Jun"}],"mainEntityOfPage":{"@type":"WebPage","@id":"https://rich-junwang.github.io/en-us/posts/tech/cloud/aws/"},"publisher":{"@type":"Organization","name":"Jun's Blog","logo":{"@type":"ImageObject","url":"https://rich-junwang.github.io/img/Q.gif"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://rich-junwang.github.io/en-us/ accesskey=h title="Jun's Blog (Alt + H)"><img src=https://rich-junwang.github.io/img/Q.gif alt=logo aria-label=logo height=35>Jun's Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)">
<svg id="moon" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li></ul></div></div><ul id=menu><li><a href=https://rich-junwang.github.io/en-us/ title="ğŸ  Home"><span>ğŸ  Home</span></a></li><li><a href=https://rich-junwang.github.io/en-us/about title="ğŸ™‹ğŸ»â€â™‚ï¸ About"><span>ğŸ™‹ğŸ»â€â™‚ï¸ About</span></a></li><li><a href=https://rich-junwang.github.io/en-us/posts title="ğŸ“š Posts"><span>ğŸ“š Posts</span></a></li><li><a href=https://rich-junwang.github.io/en-us/tags title="ğŸ§© Tags"><span>ğŸ§© Tags</span></a></li><li><a href=https://rich-junwang.github.io/en-us/archives/ title="â±ï¸ Archives"><span>â±ï¸ Archives</span></a></li><li><a href=https://rich-junwang.github.io/en-us/search title="ğŸ” Search (Alt + /)" accesskey=/><span>ğŸ” Search</span></a></li></ul></nav></header><main class="main page"><style>i[id*=post_meta_style]{display:flex;align-items:center;margin:0 0 10px}</style><article class=post-single><div id=single-content><header class=post-header><div class=breadcrumbs><a href=https://rich-junwang.github.io/en-us/>ğŸ  Home</a>&nbsp;Â»&nbsp;<a href=https://rich-junwang.github.io/en-us/posts/>ğŸ“šArticles</a>&nbsp;Â»&nbsp;<a href=https://rich-junwang.github.io/en-us/posts/tech/>ğŸ‘¨ğŸ»â€ğŸ’» Tech</a></div><h1 class=post-title>A Walk in the Cloud</h1><div class=post-description>AWS</div><div class=post-meta><style>i[id*=post_meta_style]{display:flex;align-items:center;margin:0 0 10px}.parent-post-meta{display:flex;flex-wrap:wrap;opacity:.8}</style><span class=parent-post-meta><span id=post_meta_style_1><span class="fa fa-calendar-check-o"></span>
<span>2022-05-05
&nbsp;&nbsp;
</span></span><span id=post_meta_style_3><span class="fa fa-file-word-o"></span>
<span>1104 words
&nbsp;&nbsp;
</span></span><span id=post_meta_style_4><span class="fa fa-clock-o"></span>
<span>3 min
&nbsp;&nbsp;
</span></span><span id=post_meta_style_5><span class="fa fa-user-o"></span>
<span>Jun
&nbsp;&nbsp;
</span></span><span id=post_meta_style_6><span class="fa fa-tags" style=opacity:.8></span>
<span><span class=post-tags-meta><a href=https://rich-junwang.github.io/en-us/tags/tech/ style="color:var(--secondary) !important">Tech</a>
</span></span></span></span><span style=opacity:.8><span id=post_meta_style_7>&nbsp;&nbsp;
<span class="fa fa-eye"></span>
<span><span id=busuanzi_container_page_pv><span id=busuanzi_value_page_pv></span></span>
&nbsp;&nbsp;
</span></span><span id=post_meta_style_8><span class="fa fa-commenting-o"></span>
<span><script src=https://cdn.staticfile.org/twikoo/1.5.8/twikoo.all.min.js></script><script>let url=document.documentURI,dnsUrl="https://rich-junwang.github.io/",urlSplit=url.split(dnsUrl),finalUrl=urlSplit[1];finalUrl[0]!=="/"&&(finalUrl="/"+finalUrl),twikoo.getCommentsCount({envId:null,region:null,urls:[finalUrl],includeReply:!1}).then(function(e){let t=e[0].count;const n=document.getElementById("comment_count");n.innerText=t}).catch(function(e){console.error(e)})</script><span id=comment_count></span></span></span></span></div></header><aside id=toc-container class="toc-container wide"><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#ecr aria-label=ECR>ECR</a></li><li><a href=#gitlab-and-github aria-label="GitLab and Github">GitLab and Github</a></li><li><a href=#common-aws-cli aria-label="Common AWS CLI">Common AWS CLI</a></li><li><a href=#cloudwatch aria-label=CloudWatch>CloudWatch</a></li><li><a href=#vpc-and-security-group aria-label="VPC and Security Group">VPC and Security Group</a></li><li><a href=#efs aria-label=EFS>EFS</a></li><li><a href=#eks aria-label=EKS>EKS</a></li><li><a href=#fsx-for-lustre aria-label="FSx for Lustre">FSx for Lustre</a><ul><li><a href=#fsx-and-s3 aria-label="FSx and S3">FSx and S3</a></li></ul></li></ul></div></details></div></aside><script>let activeElement,elements;window.addEventListener("DOMContentLoaded",function(){checkTocPosition(),elements=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]"),activeElement=elements[0];const t=encodeURI(activeElement.getAttribute("id")).toLowerCase();document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active")},!1),window.addEventListener("resize",function(){checkTocPosition()},!1),window.addEventListener("scroll",()=>{elements&&(activeElement=Array.from(elements).find(e=>{if(getOffsetTop(e)-window.pageYOffset>0&&getOffsetTop(e)-window.pageYOffset<window.innerHeight/2)return e})||activeElement,elements.forEach(e=>{const t=encodeURI(e.getAttribute("id")).toLowerCase();e===activeElement?document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active"):document.querySelector(`.inner ul li a[href="#${t}"]`).classList.remove("active")}))},!1);const main=parseInt(getComputedStyle(document.body).getPropertyValue("--article-width"),10),toc=parseInt(getComputedStyle(document.body).getPropertyValue("--toc-width"),10),gap=parseInt(getComputedStyle(document.body).getPropertyValue("--gap"),10);function checkTocPosition(){const e=document.body.scrollWidth;e-main-toc*2-gap*4>0?document.getElementById("toc-container").classList.add("wide"):document.getElementById("toc-container").classList.remove("wide")}function getOffsetTop(e){if(!e.getClientRects().length)return 0;let t=e.getBoundingClientRect(),n=e.ownerDocument.defaultView;return t.top+n.pageYOffset}</script><div class=post-content><p>In this doc, I keep record of some commonly used aws related commands for my quick reference. I&rsquo;ll be very glad if this could be somewhat helpful to you.</p><h3 id=ecr>ECR<a hidden class=anchor aria-hidden=true href=#ecr>#</a></h3><p>ECR login</p><p>For aws-cli 2.7 or above version, use the command below:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># check all images</span>
</span></span><span style=display:flex><span>aws ecr describe-repositories
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># login the docker</span>
</span></span><span style=display:flex><span>aws ecr get-login-password --region &lt;region&gt; | docker login --username AWS --password-stdin &lt;aws_account_id&gt;.dkr.ecr.&lt;region&gt;.amazonaws.com
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># we can get the aws account id using the following command</span>
</span></span><span style=display:flex><span>aws ecr get-login-password --region &lt;region&gt; | docker login --username AWS --password-stdin <span style=color:#e6db74>&#34;</span><span style=color:#66d9ef>$(</span>aws sts get-caller-identity --query Account --output text<span style=color:#66d9ef>)</span><span style=color:#e6db74>.dkr.ecr.&lt;region&gt;.amazonaws.com&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># pull the image</span>
</span></span><span style=display:flex><span>docker pull &lt;image_name&gt;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># If we pushed the image using sudo, then pull also add sudo</span>
</span></span><span style=display:flex><span>sudo docker pull &lt;image_name&gt;
</span></span></code></pre></div><p>Sometimes we need one image in one region, but it&rsquo;s pushed to another region. We can do the dollowing steps to push the image to target region.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># login to the region where the image current is. Here assume it&#39;s in us-east-1</span>
</span></span><span style=display:flex><span>REGION<span style=color:#f92672>=</span>us-east-1 ; aws ecr get-login-password --region <span style=color:#e6db74>${</span>REGION<span style=color:#e6db74>}</span> | docker login --username AWS --password-stdin &lt;aws_account_id&gt;.dkr.ecr.<span style=color:#e6db74>${</span>REGION<span style=color:#e6db74>}</span>.amazonaws.com
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Then pull the image from ECR</span>
</span></span><span style=display:flex><span>docker pull image_name
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Find out the image id</span>
</span></span><span style=display:flex><span>docker image ls | grep image_name | cut -f3 
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># tag</span>
</span></span><span style=display:flex><span>docker tag  image_id new_image_tag_with_new_region
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># login to the new region</span>
</span></span><span style=display:flex><span>REGION<span style=color:#f92672>=</span>us-west-2 ; aws ecr get-login-password --region <span style=color:#e6db74>${</span>REGION<span style=color:#e6db74>}</span> | docker login --username AWS --password-stdin &lt;aws_account_id&gt;.dkr.ecr.<span style=color:#e6db74>${</span>REGION<span style=color:#e6db74>}</span>.amazonaws.com
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># push</span>
</span></span><span style=display:flex><span>docker push new_image_tag_with_new_region
</span></span></code></pre></div><h3 id=gitlab-and-github>GitLab and Github<a hidden class=anchor aria-hidden=true href=#gitlab-and-github>#</a></h3><p>Gitlab changes its authentication methods and the way it works is almost identical to Github. The easiest way to use it is through personal token.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span># For gitlab usage
</span></span><span style=display:flex><span># clone a repo using personal token
</span></span><span style=display:flex><span>git clone https://oauth2:personal_token@gitlab.com/username/project.git
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>git remote set-url origin https://oauth2:personal_token@gitlab.com/username/project.git
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>git push https://personal_token@gitlab.com/username/project.git
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>## For github usage
</span></span><span style=display:flex><span>git clone https://username:personal_token@github.com/username/project.git .
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>git remote set-url origin https://username:personal_token@github.com/username/project.git
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>git push https://personal_token@github.com/username/project.git
</span></span></code></pre></div><p>Another simpler way to clone personal repo on a new machine
(1) Add ssh public key into github/gitlab webpage. settings -> ssh and GPG keys -> add ssh key.
(2) To clone a repo, use ssh link. <a href=mailto:git@github.com>git@github.com</a>:xxx</p><p>We can also use https to clone a repo, but need to add personal access token from github.</p><h3 id=common-aws-cli>Common AWS CLI<a hidden class=anchor aria-hidden=true href=#common-aws-cli>#</a></h3><p>To get the current region,</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>aws configure get region
</span></span><span style=display:flex><span><span style=color:#75715e># if using the profile</span>
</span></span><span style=display:flex><span>aws configure get region --profile $PROFILE_NAME
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># aws sync with exclude</span>
</span></span><span style=display:flex><span>aws s3 sync s3://my-first-bucket s3://my-second-bucket --exclude <span style=color:#e6db74>&#39;datasets/*&#39;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># get the identity</span>
</span></span><span style=display:flex><span>aws sts get-caller-identity
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># export credentials</span>
</span></span><span style=display:flex><span>export <span style=color:#66d9ef>$(</span>ada credentials print --account xxx --role myrole --provider<span style=color:#f92672>=</span>myprovider --profile my_profile --format env | xargs -L 1<span style=color:#66d9ef>)</span>
</span></span></code></pre></div><h3 id=cloudwatch>CloudWatch<a hidden class=anchor aria-hidden=true href=#cloudwatch>#</a></h3><p>To use cloudwatch insight, we can use the following query</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>fields @timestamp, @message, @logStream
</span></span><span style=display:flex><span>| filter @logStream like /xxxxx/
</span></span><span style=display:flex><span>| sort @timestamp desc
</span></span><span style=display:flex><span>| limit <span style=color:#ae81ff>10000</span> 
</span></span></code></pre></div><h3 id=vpc-and-security-group>VPC and Security Group<a hidden class=anchor aria-hidden=true href=#vpc-and-security-group>#</a></h3><p>Security group controls how we login the instance (like through ssh etc)
VPC determines what kind of resource we can visit from the instance. For instance if we are able to access specific EFS and FSx.
Private VPC subnet will require a bastion to connect to instance.</p><p align=center><img alt=VPC src=images/vpc.png width=80%>
kubernetes architecture, image from [1]</p><p>An Internet Gateway is a logical connection between a VPC and the Internet. If there is no Internet Gateway, then the VPC has no direct access to the Internet. (However, Internet access might be provided via a Transit Gateway, which itself would need an Internet Gateway.)</p><p>Think of the Internet Gateway as the wire that you use to connect your home router to the Internet. Pull out that wire and your home network won&rsquo;t be connected to the Internet.</p><p>A subnet is a &lsquo;public subnet&rsquo; if it has a Route Table that references an Internet Gateway.</p><p>A NAT Gateway receives traffic from a VPC, forwards it to the Internet and then returns the response that was received. It must live in a public subnet because it needs to communicate with the Internet (and therefore needs a route to the Internet Gateway).</p><p>Resources in a private subnet (which, by definition, cannot route to the Internet Gateway) will have their Internet-bound requests sent to the NAT Gateway (due to a Route Table configuration). The NAT Gateway will then forward that request to the Internet and return the response that was received from the Internet.</p><p>NAT Gateways exist because organizations want the additional security offered by private subnets, which guarantee that there is no inbound access from the Internet. Similar security can be provided with a Security Group, so private subnets aren&rsquo;t actually required. However, people who are familiar with traditional (non-cloud) networking are familiar with the concept of public and private subnets, so they want to replicate that architecture in the cloud. Physical network routers only apply rules at the boundary of subnets, whereas Security Groups can be applied individually to each Resource. It&rsquo;s a bit like giving each resource its own router.</p><p>You are right that all of the above is implemented as a virtual network. There is no physical device called an Internet Gateway or a NAT Gateway. Much of it is logical routing, although the NAT Gateway does involve launching infrastructure behind-the-scenes (probably on the same infrastructure that runs EC2 instances). The NAT Gateway only connects to one VPC &ndash; it is not a &lsquo;shared service&rsquo; like Amazon S3, which is available to many AWS users simultaneously.</p><p>You also mention performing work &lsquo;manually&rsquo;. An entire VPC (including subnets, route tables, Internet Gateway, NAT Gateway, Security Groups) can be deployed automatically using an AWS CloudFormation template, or via the VPC Wizard in the VPC management console.</p><h3 id=efs>EFS<a hidden class=anchor aria-hidden=true href=#efs>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># install efs-utils, depends on platform, it could be different.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Then</span>
</span></span><span style=display:flex><span>mkdir $HOME/efs
</span></span><span style=display:flex><span>sudo mount -t efs efs_id $HOME/efs
</span></span></code></pre></div><h3 id=eks>EKS<a hidden class=anchor aria-hidden=true href=#eks>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># create an eks without node group</span>
</span></span><span style=display:flex><span>eksctl create cluster --region us-east-1 --without-nodegroup --vpc-public-subnets <span style=color:#e6db74>${</span>subnets<span style=color:#e6db74>}</span> 
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># dry run</span>
</span></span><span style=display:flex><span>eksctl create cluster -f ./eks.yaml --dry-run
</span></span></code></pre></div><p>When use cloudformation to create eks node group, the hardware could fail. We can use the following command to check the failure. The first failure in the stack (the resource provision is in a certain order) is usually what we&rsquo;re looking for.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>aws cloudformation describe-stack-events --stack-name my-cluster-stack-name
</span></span></code></pre></div><p>To delete a failed stack</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>aws cloudformation delete-stack --stack-name my-cluster-stack-name
</span></span></code></pre></div><h3 id=fsx-for-lustre>FSx for Lustre<a hidden class=anchor aria-hidden=true href=#fsx-for-lustre>#</a></h3><p>Lustre (linux + cluster) is a high performance file system. FSx for lustre is an aws managed service to launch and run for lustre file system.</p><h4 id=fsx-and-s3>FSx and S3<a hidden class=anchor aria-hidden=true href=#fsx-and-s3>#</a></h4><p>s3 is long-term durable storage. FSx for lustre is used when processing data. Usually FSx is used as a high performance file system linked into s3 bucket.</p><ol><li>Store your data on s3</li><li>Create an FSx file system and link it to your s3 bucket</li><li>At any time, use a lustre command to write changes back to s3</li><li>Delete FSx file system when you&rsquo;re done processing</li></ol></div><footer class=post-footer><nav class=paginav><a class=prev href=https://rich-junwang.github.io/en-us/posts/read/trade_war/><span class=title>Â«</span><br><span>Trade War</span>
</a><a class=next href=https://rich-junwang.github.io/en-us/posts/tech/tech/><span class=title>Â»</span><br><span>Tech & Talents</span></a></nav></footer></div><style>.comments_details summary::marker{font-size:20px;content:'ğŸ‘‰Comment';color:var(--content)}.comments_details[open] summary::marker{font-size:20px;content:'ğŸ‘‡Collapse';color:var(--content)}</style><div><details class=comments_details><summary style="cursor:pointer;margin:50px 0 20px;width:130px"><span style=font-size:20px;color:var(--content)>...</span></summary><div id=tcomment></div></details><script src=https://cdn.staticfile.org/twikoo/1.5.8/twikoo.all.min.js></script><script>twikoo.init({envId:null,el:"#tcomment",lang:"en-us",region:null,path:window.TWIKOO_MAGIC_PATH||window.location.pathname})</script></div></article></main><footer class=footer><span>Copyright
&copy;
2020-2025
<a href=https://rich-junwang.github.io/en-us/ style=color:#939393>Jun's Blog</a>
All Rights Reserved
</span><a href=https://beian.miit.gov.cn/ target=_blank style=color:#939393></a>&nbsp;
<span id=busuanzi_container><span class="fa fa-user"></span> <span id=busuanzi_value_site_uv></span>
<span class="fa fa-eye"></span> <span id=busuanzi_value_site_pv></span></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><span class=topInner><svg class="topSvg" viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
<span id=read_progress></span>
</span></a><script>document.addEventListener("scroll",function(){const t=document.getElementById("read_progress"),n=document.documentElement.scrollHeight,s=document.documentElement.clientHeight,o=document.documentElement.scrollTop||document.body.scrollTop;t.innerText=((o/(n-s)).toFixed(2)*100).toFixed(0)})</script><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>let mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>200||document.documentElement.scrollTop>200?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{(function(){document.cookie="change-themes="+escape("false")})(),document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.body.addEventListener("copy",function(e){if(window.getSelection().toString()&&window.getSelection().toString().length>50){let t=e.clipboardData||window.clipboardData;if(t){e.preventDefault();let n=window.getSelection().toString()+`\r

â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\r
ç‰ˆæƒå£°æ˜ï¼šæœ¬æ–‡ä¸ºã€ŒJun's Blogã€çš„åŸåˆ›æ–‡ç« ï¼Œéµå¾ªCC 4.0 BY-SAç‰ˆæƒåè®®ï¼Œè½¬è½½è¯·é™„ä¸ŠåŸæ–‡å‡ºå¤„é“¾æ¥åŠæœ¬å£°æ˜ã€‚\r
åŸæ–‡é“¾æ¥ï¼š`+location.href,s=window.getSelection().toString()+`\r

â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\r
ç‰ˆæƒå£°æ˜ï¼šæœ¬æ–‡ä¸ºã€ŒJun's Blogã€çš„åŸåˆ›æ–‡ç« ï¼Œéµå¾ªCC 4.0 BY-SAç‰ˆæƒåè®®ï¼Œè½¬è½½è¯·é™„ä¸ŠåŸæ–‡å‡ºå¤„é“¾æ¥åŠæœ¬å£°æ˜ã€‚\r
åŸæ–‡é“¾æ¥ï¼š`+location.href;t.setData("text/html",n),t.setData("text/plain",s)}}})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const s=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerText="copy";function i(){t.innerText="copied!",setTimeout(()=>{t.innerText="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){let t=e.textContent+`\r
â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\r
ç‰ˆæƒå£°æ˜ï¼šæœ¬æ–‡ä¸ºã€ŒJun's Blogã€çš„åŸåˆ›æ–‡ç« ï¼Œéµå¾ªCC 4.0 BY-SAç‰ˆæƒåè®®ï¼Œè½¬è½½è¯·é™„ä¸ŠåŸæ–‡å‡ºå¤„é“¾æ¥åŠæœ¬å£°æ˜ã€‚\r
åŸæ–‡é“¾æ¥ï¼š`+location.href;navigator.clipboard.writeText(t),i();return}const n=document.createRange();n.selectNodeContents(e);const s=window.getSelection();s.removeAllRanges(),s.addRange(n);try{document.execCommand("copy"),i()}catch{}s.removeRange(n)});let l=e.className.replaceAll("language-",""),n=document.createElement("div"),a=document.createElement("div"),r=document.createElement("div"),c=document.createElement("div"),o=document.createElement("div");o.innerText=l,n.setAttribute("class","mac-tool"),a.setAttribute("class","mac bb1"),r.setAttribute("class","mac bb2"),c.setAttribute("class","mac bb3"),o.setAttribute("class","language-type"),n.appendChild(a),n.appendChild(r),n.appendChild(c),n.appendChild(o),s.classList.contains("highlight")?(s.appendChild(t),s.appendChild(n)):s.parentNode.firstChild==s||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?(e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t),s.appendChild(n)):(e.parentNode.appendChild(t),s.appendChild(n)))})</script></body></html>
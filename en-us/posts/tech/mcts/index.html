<!doctype html><html lang=en-us dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Monte Carlo Tree Search | Jun's Blog</title>
<meta name=keywords content><meta name=description content="MCTS"><meta name=author content="Jun"><link rel=canonical href=https://rich-junwang.github.io/en-us/posts/tech/mcts/><link crossorigin=anonymous href=/assets/css/stylesheet.css rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.js onload=hljs.initHighlightingOnLoad()></script><link rel=icon href=https://rich-junwang.github.io/img/Q.gif><link rel=icon type=image/png sizes=16x16 href=https://rich-junwang.github.io/img/Q.gif><link rel=icon type=image/png sizes=32x32 href=https://rich-junwang.github.io/img/Q.gif><link rel=apple-touch-icon href=https://rich-junwang.github.io/img/Q.gif><link rel=mask-icon href=https://rich-junwang.github.io/img/Q.gif><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en-us href=https://rich-junwang.github.io/en-us/posts/tech/mcts/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script defer src=https://unpkg.com/mermaid@8.8.1/dist/mermaid.min.js></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/font-awesome@4.7.0/css/font-awesome.min.css><script src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script><script src=https://cdn.jsdelivr.net/npm/jquery@3.6.3/dist/jquery.min.js></script><script>var _hmt=_hmt||[];(function(){var e,t=document.createElement("script");t.src="",e=document.getElementsByTagName("script")[0],e.parentNode.insertBefore(t,e)})()</script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css integrity=sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js integrity=sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js integrity=sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa crossorigin=anonymous onload='renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"\\[",right:"\\]",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1}]})'></script><meta property="og:title" content="Monte Carlo Tree Search"><meta property="og:description" content="MCTS"><meta property="og:type" content="article"><meta property="og:url" content="https://rich-junwang.github.io/en-us/posts/tech/mcts/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-04-05T00:18:23+08:00"><meta property="article:modified_time" content="2024-04-05T00:18:23+08:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Monte Carlo Tree Search"><meta name=twitter:description content="MCTS"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"ğŸ“šArticles","item":"https://rich-junwang.github.io/en-us/posts/"},{"@type":"ListItem","position":2,"name":"ğŸ‘¨ğŸ»â€ğŸ’» Tech","item":"https://rich-junwang.github.io/en-us/posts/tech/"},{"@type":"ListItem","position":3,"name":"Monte Carlo Tree Search","item":"https://rich-junwang.github.io/en-us/posts/tech/mcts/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Monte Carlo Tree Search","name":"Monte Carlo Tree Search","description":"MCTS","keywords":[""],"articleBody":"In this blog, we talk about Monte Carlo Tree Search, the algorithm behind very popular AlphaZero.\nDuel Process Human cognition has a duel process model which suggests that human reason has two modes. System 1 is a fast, unconscious and automatic mode of thought,like intuition. System 2 is a slow, conscious, explicit and rule-based mode of reasoning.\nComparing with how LLM works, we can think about that token-level generation is like System 1 mode, and agent planning, lookahead and backtracks is the System 2 mode.\nMCTS The main concept of MCTS is a search. Search is tree traversals of the game tree. Single traversal is a path from a root node (current game state) to a node that is not fully expanded. Node being not-fully expanded means at least one of its children is unvisited, not explored. Once not fully expanded node is encountered, one of its unvisited children is chosen to become a root node for a single playout/simulation. The result of the simulation is then propagated back up to the current tree root updating game tree nodes statistics. Once the search (constrained by time or computational power) terminates, the move is chosen based on the gathered statistics. Thus, the algorithm of the tree traversal in MCTS follows the following steps:\nSelection: select an unvisited node based on tree policy Expansion: whether to expand a node or skip it if itâ€™s visited Simulation/Evaluation: a full play starts in current node (representing game state) and ends in a terminal node where game result can be computed. One simulation expansion is shown below. Backpropagation: Backpropagate result to all nodes in the traversal chain up to the current game tree root node. Figure 1. Simulation in MCTS, image from Ref 3 Modeling From the above process, we can see that there are two key problems that needs to be addressed in MCTS.\nFirst is the node selection. How do we select which node to explore. Basically this defines how we explore all action space. Second simulation. How do we get the current traversal evaluated. Before answering these question, we first have to keep record of the game tree traversal simulation results. Weâ€™ll need to maintain a few values for each node:\nâ€“ $Q(v)$ is total simulation reward is an attribute of a node $v$ and in a simplest form is a sum of simulation results that passed through considered node.\nâ€“ $N(v)$ is total number of visits. Itâ€™s another atribute of a node $v$ representing a counter of how many times a node has been on the backpropagation path (and so how many times it contributed to the total simulation reward)\nThese node statistics reflects the exploitation and exploration in the algorithm. Nodes with high reward are good candidates to follow (exploitation) but those with low amount of visits may be interesting too as they are not explored well.\nSelection UCT Upper Confidence Bound applied to trees (UCT) is the function used for node selection when traverse the tree. For node $v$ with child node $v_i$, we define the UCT function as follows: $$ UCT(v_i, v) = \\frac{Q(v_i)}{N(v_i)} + c \\sqrt{\\frac{log(N(v))}{N(v_i)}} $$\nwhere $c$ is a hyperparameter which is used to balance exploitation and exploration. The first part is exploitation component which qualifies the winning rate of a particular child. However, only exploitation component is not enough because it will lead to greedily exploring only those nodes that bring a single winning playout very early at the beginning of the search.\nThe second component of UCT called exploration component which favors nodes that have not been explored.\nPUCT Predictor UCT is from Ref 5, it adds prior of the preference of a particular node. $$ PUCT(v_i, v) = \\frac{Q(v_i)}{N(v_i)} + c P(v, v_i) \\frac{\\sqrt{N(v)}}{1 + N(v_i)} $$\nReferences Thinking Fast and Slow with Deep Learning and Tree Search Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm https://int8.io/monte-carlo-tree-search-beginners-guide Bandit based Monte-Carlo Planning Multi-armed bandits with episode context ","wordCount":"658","inLanguage":"en-us","datePublished":"2024-04-05T00:18:23+08:00","dateModified":"2024-04-05T00:18:23+08:00","author":[{"@type":"Person","name":"Jun"}],"mainEntityOfPage":{"@type":"WebPage","@id":"https://rich-junwang.github.io/en-us/posts/tech/mcts/"},"publisher":{"@type":"Organization","name":"Jun's Blog","logo":{"@type":"ImageObject","url":"https://rich-junwang.github.io/img/Q.gif"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://rich-junwang.github.io/en-us/ accesskey=h title="Jun's Blog (Alt + H)"><img src=https://rich-junwang.github.io/img/Q.gif alt=logo aria-label=logo height=35>Jun's Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li></ul></div></div><ul id=menu><li><a href=https://rich-junwang.github.io/en-us/ title="ğŸ  Home"><span>ğŸ  Home</span></a></li><li><a href=https://rich-junwang.github.io/en-us/about title="ğŸ™‹ğŸ»â€â™‚ï¸ About"><span>ğŸ™‹ğŸ»â€â™‚ï¸ About</span></a></li><li><a href=https://rich-junwang.github.io/en-us/posts title="ğŸ“š Posts"><span>ğŸ“š Posts</span></a></li><li><a href=https://rich-junwang.github.io/en-us/tags title="ğŸ§© Tags"><span>ğŸ§© Tags</span></a></li><li><a href=https://rich-junwang.github.io/en-us/archives/ title="â±ï¸ Archives"><span>â±ï¸ Archives</span></a></li><li><a href=https://rich-junwang.github.io/en-us/search title="ğŸ” Search (Alt + /)" accesskey=/><span>ğŸ” Search</span></a></li></ul></nav></header><main class="main page"><style>i[id*=post_meta_style]{display:flex;align-items:center;margin:0 0 10px}</style><article class=post-single><div id=single-content><header class=post-header><div class=breadcrumbs><a href=https://rich-junwang.github.io/en-us/>ğŸ  Home</a>&nbsp;Â»&nbsp;<a href=https://rich-junwang.github.io/en-us/posts/>ğŸ“šArticles</a>&nbsp;Â»&nbsp;<a href=https://rich-junwang.github.io/en-us/posts/tech/>ğŸ‘¨ğŸ»â€ğŸ’» Tech</a></div><h1 class=post-title>Monte Carlo Tree Search</h1><div class=post-description>MCTS</div><div class=post-meta><style>i[id*=post_meta_style]{display:flex;align-items:center;margin:0 0 10px}.parent-post-meta{display:flex;flex-wrap:wrap;opacity:.8}</style><span class=parent-post-meta><span id=post_meta_style_1><span class="fa fa-calendar-check-o"></span>
<span>2024-04-05
&nbsp;&nbsp;
</span></span><span id=post_meta_style_3><span class="fa fa-file-word-o"></span>
<span>658 words
&nbsp;&nbsp;
</span></span><span id=post_meta_style_4><span class="fa fa-clock-o"></span>
<span>2 min
&nbsp;&nbsp;
</span></span><span id=post_meta_style_5><span class="fa fa-user-o"></span>
<span>Jun
&nbsp;&nbsp;
</span></span><span id=post_meta_style_6><span class="fa fa-tags" style=opacity:.8></span>
<span><span class=post-tags-meta><a href=https://rich-junwang.github.io/en-us/tags/ml/ style=color:var(--secondary)!important>ML</a>
</span></span></span></span><span style=opacity:.8><span id=post_meta_style_7>&nbsp;&nbsp;
<span class="fa fa-eye"></span>
<span><span id=busuanzi_container_page_pv><span id=busuanzi_value_page_pv></span></span>
&nbsp;&nbsp;
</span></span><span id=post_meta_style_8><span class="fa fa-commenting-o"></span>
<span><script src=https://cdn.staticfile.org/twikoo/1.5.8/twikoo.all.min.js></script><script>let url=document.documentURI,dnsUrl="https://rich-junwang.github.io/",urlSplit=url.split(dnsUrl),finalUrl=urlSplit[1];finalUrl[0]!=="/"&&(finalUrl="/"+finalUrl),twikoo.getCommentsCount({envId:null,region:null,urls:[finalUrl],includeReply:!1}).then(function(e){let t=e[0].count;const n=document.getElementById("comment_count");n.innerText=t}).catch(function(e){console.error(e)})</script><span id=comment_count></span></span></span></span></div></header><aside id=toc-container class="toc-container wide"><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#duel-process aria-label="Duel Process">Duel Process</a></li><li><a href=#mcts aria-label=MCTS>MCTS</a></li><li><a href=#modeling aria-label=Modeling>Modeling</a></li><li><a href=#selection aria-label=Selection>Selection</a><ul><li><a href=#uct aria-label=UCT>UCT</a></li><li><a href=#puct aria-label=PUCT>PUCT</a></li></ul></li><li><a href=#references aria-label=References>References</a></li></ul></div></details></div></aside><script>let activeElement,elements;window.addEventListener("DOMContentLoaded",function(){checkTocPosition(),elements=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]"),activeElement=elements[0];const t=encodeURI(activeElement.getAttribute("id")).toLowerCase();document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active")},!1),window.addEventListener("resize",function(){checkTocPosition()},!1),window.addEventListener("scroll",()=>{elements&&(activeElement=Array.from(elements).find(e=>{if(getOffsetTop(e)-window.pageYOffset>0&&getOffsetTop(e)-window.pageYOffset<window.innerHeight/2)return e})||activeElement,elements.forEach(e=>{const t=encodeURI(e.getAttribute("id")).toLowerCase();e===activeElement?document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active"):document.querySelector(`.inner ul li a[href="#${t}"]`).classList.remove("active")}))},!1);const main=parseInt(getComputedStyle(document.body).getPropertyValue("--article-width"),10),toc=parseInt(getComputedStyle(document.body).getPropertyValue("--toc-width"),10),gap=parseInt(getComputedStyle(document.body).getPropertyValue("--gap"),10);function checkTocPosition(){const e=document.body.scrollWidth;e-main-toc*2-gap*4>0?document.getElementById("toc-container").classList.add("wide"):document.getElementById("toc-container").classList.remove("wide")}function getOffsetTop(e){if(!e.getClientRects().length)return 0;let t=e.getBoundingClientRect(),n=e.ownerDocument.defaultView;return t.top+n.pageYOffset}</script><div class=post-content><p>In this blog, we talk about Monte Carlo Tree Search, the algorithm behind very popular AlphaZero.</p><h3 id=duel-process>Duel Process<a hidden class=anchor aria-hidden=true href=#duel-process>#</a></h3><p>Human cognition has a duel process model which suggests that human reason has two modes. System 1 is a fast, unconscious and automatic mode of thought,like intuition. System 2 is a slow, conscious, explicit and rule-based mode of reasoning.</p><p>Comparing with how LLM works, we can think about that token-level generation is like System 1 mode, and agent planning, lookahead and backtracks is the System 2 mode.</p><h3 id=mcts>MCTS<a hidden class=anchor aria-hidden=true href=#mcts>#</a></h3><p>The main concept of MCTS is a search. Search is tree traversals of the game tree. Single traversal is a path from a root node (current game state) to a node that is not fully expanded. Node being not-fully expanded means at least one of its children is unvisited, not explored. Once not fully expanded node is encountered, one of its unvisited children is chosen to become a root node for a single playout/simulation. The result of the simulation is then propagated back up to the current tree root updating game tree nodes statistics. Once the search (constrained by time or computational power) terminates, the move is chosen based on the gathered statistics. Thus, the algorithm of the tree traversal in MCTS follows the following steps:</p><ol><li>Selection: select an unvisited node based on tree policy</li><li>Expansion: whether to expand a node or skip it if it&rsquo;s visited</li><li>Simulation/Evaluation: a full play starts in current node (representing game state) and ends in a terminal node where game result can be computed. One simulation expansion is shown below.</li><li>Backpropagation: Backpropagate result to all nodes in the traversal chain up to the current game tree root node.</li></ol><p align=center><img alt=mcts src=images/simulation.png width=80% height=auto/>
Figure 1. Simulation in MCTS, image from Ref 3</p><h3 id=modeling>Modeling<a hidden class=anchor aria-hidden=true href=#modeling>#</a></h3><p>From the above process, we can see that there are two key problems that needs to be addressed in MCTS.</p><ul><li>First is the node selection. How do we select which node to explore. Basically this defines how we explore all action space.</li><li>Second simulation. How do we get the current traversal evaluated.</li></ul><p>Before answering these question, we first have to keep record of the game tree traversal simulation results. We&rsquo;ll need to maintain a few values for each node:</p><p>â€“ $Q(v)$ is total simulation reward is an attribute of a node $v$
and in a simplest form is a sum of simulation results that passed through considered node.</p><p>â€“ $N(v)$ is total number of visits. It&rsquo;s another atribute of a node $v$
representing a counter of how many times a node has been on the backpropagation path (and so how many times it contributed to the total simulation reward)</p><p>These node statistics reflects the exploitation and exploration in the algorithm. Nodes with high reward are good candidates to follow (exploitation) but those with low amount of visits may be interesting too as they are not explored well.</p><h3 id=selection>Selection<a hidden class=anchor aria-hidden=true href=#selection>#</a></h3><h4 id=uct>UCT<a hidden class=anchor aria-hidden=true href=#uct>#</a></h4><p>Upper Confidence Bound applied to trees (UCT) is the function used for node selection when traverse the tree.
For node $v$ with child node $v_i$, we define the UCT function as follows:
$$
UCT(v_i, v) = \frac{Q(v_i)}{N(v_i)} + c \sqrt{\frac{log(N(v))}{N(v_i)}}
$$</p><p>where $c$ is a hyperparameter which is used to balance exploitation and exploration. The first part is exploitation component which qualifies the winning rate of a particular child. However, only exploitation component is not enough because it will lead to greedily exploring only those nodes that bring a single winning playout very early at the beginning of the search.</p><p>The second component of UCT called exploration component which favors nodes that have not been explored.</p><h4 id=puct>PUCT<a hidden class=anchor aria-hidden=true href=#puct>#</a></h4><p>Predictor UCT is from Ref 5, it adds prior of the preference of a particular node.
$$
PUCT(v_i, v) = \frac{Q(v_i)}{N(v_i)} + c P(v, v_i) \frac{\sqrt{N(v)}}{1 + N(v_i)}
$$</p><h3 id=references>References<a hidden class=anchor aria-hidden=true href=#references>#</a></h3><ol><li><a href=https://arxiv.org/abs/1705.08439>Thinking Fast and Slow with Deep Learning and Tree Search</a></li><li><a href=https://arxiv.org/abs/1712.01815>Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm</a></li><li><a href=https://int8.io/monte-carlo-tree-search-beginners-guide>https://int8.io/monte-carlo-tree-search-beginners-guide</a></li><li><a href=http://ggp.stanford.edu/readings/uct.pdf>Bandit based Monte-Carlo Planning</a></li><li>Multi-armed bandits with episode context</li></ol></div><footer class=post-footer><nav class=paginav><a class=prev href=https://rich-junwang.github.io/en-us/posts/tech/diffusion/><span class=title>Â«</span><br><span>Diffusion Probabilistic Models</span>
</a><a class=next href=https://rich-junwang.github.io/en-us/posts/tech/ml_system/><span class=title>Â»</span><br><span>ML System</span></a></nav></footer></div><style>.comments_details summary::marker{font-size:20px;content:'ğŸ‘‰Comment';color:var(--content)}.comments_details[open] summary::marker{font-size:20px;content:'ğŸ‘‡Collapse';color:var(--content)}</style><div><details class=comments_details><summary style="cursor:pointer;margin:50px 0 20px;width:130px"><span style=font-size:20px;color:var(--content)>...</span></summary><div id=tcomment></div></details><script src=https://cdn.staticfile.org/twikoo/1.5.8/twikoo.all.min.js></script><script>twikoo.init({envId:null,el:"#tcomment",lang:"en-us",region:null,path:window.TWIKOO_MAGIC_PATH||window.location.pathname})</script></div></article></main><footer class=footer><span>Copyright
&copy;
2020-2024
<a href=https://rich-junwang.github.io/en-us/ style=color:#939393>Jun's Blog</a>
All Rights Reserved
</span><a href=https://beian.miit.gov.cn/ target=_blank style=color:#939393></a>&nbsp;
<span id=busuanzi_container><span class="fa fa-user"></span> <span id=busuanzi_value_site_uv></span>
<span class="fa fa-eye"></span> <span id=busuanzi_value_site_pv></span></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><span class=topInner><svg class="topSvg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
<span id=read_progress></span>
</span></a><script>document.addEventListener("scroll",function(){const t=document.getElementById("read_progress"),n=document.documentElement.scrollHeight,s=document.documentElement.clientHeight,o=document.documentElement.scrollTop||document.body.scrollTop;t.innerText=((o/(n-s)).toFixed(2)*100).toFixed(0)})</script><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>let mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>200||document.documentElement.scrollTop>200?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{(function(){document.cookie="change-themes="+escape("false")})(),document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.body.addEventListener("copy",function(e){if(window.getSelection().toString()&&window.getSelection().toString().length>50){let t=e.clipboardData||window.clipboardData;if(t){e.preventDefault();let n=window.getSelection().toString()+`\r

â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\r
ç‰ˆæƒå£°æ˜ï¼šæœ¬æ–‡ä¸ºã€ŒJun's Blogã€çš„åŸåˆ›æ–‡ç« ï¼Œéµå¾ªCC 4.0 BY-SAç‰ˆæƒåè®®ï¼Œè½¬è½½è¯·é™„ä¸ŠåŸæ–‡å‡ºå¤„é“¾æ¥åŠæœ¬å£°æ˜ã€‚\r
åŸæ–‡é“¾æ¥ï¼š`+location.href,s=window.getSelection().toString()+`\r

â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\r
ç‰ˆæƒå£°æ˜ï¼šæœ¬æ–‡ä¸ºã€ŒJun's Blogã€çš„åŸåˆ›æ–‡ç« ï¼Œéµå¾ªCC 4.0 BY-SAç‰ˆæƒåè®®ï¼Œè½¬è½½è¯·é™„ä¸ŠåŸæ–‡å‡ºå¤„é“¾æ¥åŠæœ¬å£°æ˜ã€‚\r
åŸæ–‡é“¾æ¥ï¼š`+location.href;t.setData("text/html",n),t.setData("text/plain",s)}}})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const s=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerText="copy";function i(){t.innerText="copied!",setTimeout(()=>{t.innerText="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){let t=e.textContent+`\r
â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\r
ç‰ˆæƒå£°æ˜ï¼šæœ¬æ–‡ä¸ºã€ŒJun's Blogã€çš„åŸåˆ›æ–‡ç« ï¼Œéµå¾ªCC 4.0 BY-SAç‰ˆæƒåè®®ï¼Œè½¬è½½è¯·é™„ä¸ŠåŸæ–‡å‡ºå¤„é“¾æ¥åŠæœ¬å£°æ˜ã€‚\r
åŸæ–‡é“¾æ¥ï¼š`+location.href;navigator.clipboard.writeText(t),i();return}const n=document.createRange();n.selectNodeContents(e);const s=window.getSelection();s.removeAllRanges(),s.addRange(n);try{document.execCommand("copy"),i()}catch{}s.removeRange(n)});let l=e.className.replaceAll("language-",""),n=document.createElement("div"),a=document.createElement("div"),r=document.createElement("div"),c=document.createElement("div"),o=document.createElement("div");o.innerText=l,n.setAttribute("class","mac-tool"),a.setAttribute("class","mac bb1"),r.setAttribute("class","mac bb2"),c.setAttribute("class","mac bb3"),o.setAttribute("class","language-type"),n.appendChild(a),n.appendChild(r),n.appendChild(c),n.appendChild(o),s.classList.contains("highlight")?(s.appendChild(t),s.appendChild(n)):s.parentNode.firstChild==s||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?(e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t),s.appendChild(n)):(e.parentNode.appendChild(t),s.appendChild(n)))})</script></body></html>
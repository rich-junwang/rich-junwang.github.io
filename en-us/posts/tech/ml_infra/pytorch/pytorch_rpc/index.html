<!doctype html><html lang=en-us dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>RPC in Torch | Jun's Blog</title>
<meta name=keywords content><meta name=description content="PyTorch.."><meta name=author content="Jun"><link rel=canonical href=https://rich-junwang.github.io/en-us/posts/tech/ml_infra/pytorch/pytorch_rpc/><link crossorigin=anonymous href=/assets/css/stylesheet.css rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.js onload=hljs.initHighlightingOnLoad()></script><link rel=icon href=https://rich-junwang.github.io/img/Q.gif><link rel=icon type=image/png sizes=16x16 href=https://rich-junwang.github.io/img/Q.gif><link rel=icon type=image/png sizes=32x32 href=https://rich-junwang.github.io/img/Q.gif><link rel=apple-touch-icon href=https://rich-junwang.github.io/img/Q.gif><link rel=mask-icon href=https://rich-junwang.github.io/img/Q.gif><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en-us href=https://rich-junwang.github.io/en-us/posts/tech/ml_infra/pytorch/pytorch_rpc/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script defer src=https://unpkg.com/mermaid@8.8.1/dist/mermaid.min.js></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/font-awesome@4.7.0/css/font-awesome.min.css><script src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script><script src=https://cdn.jsdelivr.net/npm/jquery@3.6.3/dist/jquery.min.js></script><script>var _hmt=_hmt||[];(function(){var e,t=document.createElement("script");t.src="",e=document.getElementsByTagName("script")[0],e.parentNode.insertBefore(t,e)})()</script><meta property="og:title" content="RPC in Torch"><meta property="og:description" content="PyTorch.."><meta property="og:type" content="article"><meta property="og:url" content="https://rich-junwang.github.io/en-us/posts/tech/ml_infra/pytorch/pytorch_rpc/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-01-11T00:18:23+08:00"><meta property="article:modified_time" content="2024-01-11T00:18:23+08:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="RPC in Torch"><meta name=twitter:description content="PyTorch.."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"üìöArticles","item":"https://rich-junwang.github.io/en-us/posts/"},{"@type":"ListItem","position":2,"name":"üë®üèª‚Äçüíª Tech","item":"https://rich-junwang.github.io/en-us/posts/tech/"},{"@type":"ListItem","position":3,"name":"RPC in Torch","item":"https://rich-junwang.github.io/en-us/posts/tech/ml_infra/pytorch/pytorch_rpc/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"RPC in Torch","name":"RPC in Torch","description":"PyTorch..","keywords":[""],"articleBody":"PyTorch supports several approaches to distributed training and communication, including:\nData Parallel (DP): A legacy approach where data is split across multiple GPUs on a single machine, and model replicas are kept synchronized manually.\nCollective Communications (c10d): A low-level library providing collective communication primitives (e.g., all-reduce) for synchronizing data across multiple devices and nodes. It supports MPI, NCCL and GLOO backend.\nDistributed Data Parallel (DDP): The recommended method for scaling training across multiple GPUs and machines, where each process maintains its own model replica and gradient synchronization is performed efficiently using collective communication.\nRemote Procedure Call (RPC) Framework: A flexible framework enabling model parallelism by allowing different parts of a model to reside and execute on different devices or machines through asynchronous remote execution.\nData parallel is not really a distributed training tool which is discussed in our previous post, we‚Äôll not cover it here. In this post, we mainly want to talk about why Torch introduce TorchRPC.\nWhy RPC Conditional Communication Without RPC (only using p2p communication in torch.distributed .send/.recv), when we want to send tensor y when tensor x is ready from node A to node B, both nodes need to know ahead of time exactly what communication will happen.\nA has tensor x and wants to decide: ‚ÄúShould I send tensor y to B or not?‚Äù With just .send() and .recv(), both A and B must call these communication functions in matching order ‚Äî otherwise, they will deadlock (e.g., A is sending but B is not receiving, so both get stuck forever). The problem is B cannot ‚Äúwait to see‚Äù if A wants to send, unless B already knows whether a .recv() is needed. Therefore, B must somehow know what A decided, and in simple .send/.recv world, the only way is to first send x (the condition) to B, so B can evaluate the logic too.\nNodes Communication RPC establishes a p2p communication without requiring init_process_group. For example:\nimport multiprocessing as mp import torch def main(rank,world_size): torch.distributed.init_process_group(rank=0,world_size=1,backend='nccl',init_method=f'tcp://127.0.0.1:{29500+rank}') options = torch.distributed.rpc.TensorPipeRpcBackendOptions(init_method='tcp://127.0.0.1:30001') torch.distributed.rpc.init_rpc(f'worker-{rank}', rank=rank, world_size=world_size, rpc_backend_options=options) print(f'rank: {torch.distributed.get_rank()}', f' world_size: {torch.distributed.get_world_size()}', f' {torch.distributed.rpc.get_worker_info()}') torch.distributed.rpc.shutdown() if __name__ == '__main__': world_size = 4 ps = [mp.Process(None,main,args=(rank,world_size)) for rank in range(world_size)] for p in ps: p.start() for p in ps: p.join() P2P (.send/.recv) RPC Communication Must be prearranged on both sides Triggered by sender only Flexibility Low, hard for conditional logic High, can easily send conditionally Failure mode Deadlock if not matching No deadlock if only one side triggers Best for Simple, fixed communication Complex, dynamic, conditional logic References https://medium.com/@eeyuhao/pytorch-distributed-a-bottom-up-perspective-e3159ee2c2e7 ","wordCount":"418","inLanguage":"en-us","datePublished":"2024-01-11T00:18:23+08:00","dateModified":"2024-01-11T00:18:23+08:00","author":[{"@type":"Person","name":"Jun"}],"mainEntityOfPage":{"@type":"WebPage","@id":"https://rich-junwang.github.io/en-us/posts/tech/ml_infra/pytorch/pytorch_rpc/"},"publisher":{"@type":"Organization","name":"Jun's Blog","logo":{"@type":"ImageObject","url":"https://rich-junwang.github.io/img/Q.gif"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://rich-junwang.github.io/en-us/ accesskey=h title="Jun's Blog (Alt + H)"><img src=https://rich-junwang.github.io/img/Q.gif alt=logo aria-label=logo height=35>Jun's Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li></ul></div></div><ul id=menu><li><a href=https://rich-junwang.github.io/en-us/ title="üè† Home"><span>üè† Home</span></a></li><li><a href=https://rich-junwang.github.io/en-us/about title="üôãüèª‚Äç‚ôÇÔ∏è About"><span>üôãüèª‚Äç‚ôÇÔ∏è About</span></a></li><li><a href=https://rich-junwang.github.io/en-us/posts title="üìö Posts"><span>üìö Posts</span></a></li><li><a href=https://rich-junwang.github.io/en-us/tags title="üß© Tags"><span>üß© Tags</span></a></li><li><a href=https://rich-junwang.github.io/en-us/archives/ title="‚è±Ô∏è Archives"><span>‚è±Ô∏è Archives</span></a></li><li><a href=https://rich-junwang.github.io/en-us/search title="üîç Search (Alt + /)" accesskey=/><span>üîç Search</span></a></li></ul></nav></header><main class="main page"><style>i[id*=post_meta_style]{display:flex;align-items:center;margin:0 0 10px}</style><article class=post-single><div id=single-content><header class=post-header><div class=breadcrumbs><a href=https://rich-junwang.github.io/en-us/>üè† Home</a>&nbsp;¬ª&nbsp;<a href=https://rich-junwang.github.io/en-us/posts/>üìöArticles</a>&nbsp;¬ª&nbsp;<a href=https://rich-junwang.github.io/en-us/posts/tech/>üë®üèª‚Äçüíª Tech</a></div><h1 class=post-title>RPC in Torch</h1><div class=post-description>PyTorch..</div><div class=post-meta><style>i[id*=post_meta_style]{display:flex;align-items:center;margin:0 0 10px}.parent-post-meta{display:flex;flex-wrap:wrap;opacity:.8}</style><span class=parent-post-meta><span id=post_meta_style_1><span class="fa fa-calendar-check-o"></span>
<span>2024-01-11
&nbsp;&nbsp;
</span></span><span id=post_meta_style_3><span class="fa fa-file-word-o"></span>
<span>418 words
&nbsp;&nbsp;
</span></span><span id=post_meta_style_4><span class="fa fa-clock-o"></span>
<span>1 min
&nbsp;&nbsp;
</span></span><span id=post_meta_style_5><span class="fa fa-user-o"></span>
<span>Jun
&nbsp;&nbsp;
</span></span><span id=post_meta_style_6><span class="fa fa-tags" style=opacity:.8></span>
<span><span class=post-tags-meta><a href=https://rich-junwang.github.io/en-us/tags/infra/ style=color:var(--secondary)!important>Infra</a>
</span></span></span></span><span style=opacity:.8><span id=post_meta_style_7>&nbsp;&nbsp;
<span class="fa fa-eye"></span>
<span><span id=busuanzi_container_page_pv><span id=busuanzi_value_page_pv></span></span>
&nbsp;&nbsp;
</span></span><span id=post_meta_style_8><span class="fa fa-commenting-o"></span>
<span><script src=https://cdn.staticfile.org/twikoo/1.5.8/twikoo.all.min.js></script><script>let url=document.documentURI,dnsUrl="https://rich-junwang.github.io/",urlSplit=url.split(dnsUrl),finalUrl=urlSplit[1];finalUrl[0]!=="/"&&(finalUrl="/"+finalUrl),twikoo.getCommentsCount({envId:null,region:null,urls:[finalUrl],includeReply:!1}).then(function(e){let t=e[0].count;const n=document.getElementById("comment_count");n.innerText=t}).catch(function(e){console.error(e)})</script><span id=comment_count></span></span></span></span></div></header><aside id=toc-container class="toc-container wide"><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#why-rpc aria-label="Why RPC">Why RPC</a><ul><li><a href=#conditional-communication aria-label="Conditional Communication">Conditional Communication</a></li><li><a href=#nodes-communication aria-label="Nodes Communication">Nodes Communication</a></li></ul></li><li><a href=#references aria-label=References>References</a></li></ul></div></details></div></aside><script>let activeElement,elements;window.addEventListener("DOMContentLoaded",function(){checkTocPosition(),elements=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]"),activeElement=elements[0];const t=encodeURI(activeElement.getAttribute("id")).toLowerCase();document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active")},!1),window.addEventListener("resize",function(){checkTocPosition()},!1),window.addEventListener("scroll",()=>{elements&&(activeElement=Array.from(elements).find(e=>{if(getOffsetTop(e)-window.pageYOffset>0&&getOffsetTop(e)-window.pageYOffset<window.innerHeight/2)return e})||activeElement,elements.forEach(e=>{const t=encodeURI(e.getAttribute("id")).toLowerCase();e===activeElement?document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active"):document.querySelector(`.inner ul li a[href="#${t}"]`).classList.remove("active")}))},!1);const main=parseInt(getComputedStyle(document.body).getPropertyValue("--article-width"),10),toc=parseInt(getComputedStyle(document.body).getPropertyValue("--toc-width"),10),gap=parseInt(getComputedStyle(document.body).getPropertyValue("--gap"),10);function checkTocPosition(){const e=document.body.scrollWidth;e-main-toc*2-gap*4>0?document.getElementById("toc-container").classList.add("wide"):document.getElementById("toc-container").classList.remove("wide")}function getOffsetTop(e){if(!e.getClientRects().length)return 0;let t=e.getBoundingClientRect(),n=e.ownerDocument.defaultView;return t.top+n.pageYOffset}</script><div class=post-content><p>PyTorch supports several approaches to distributed training and communication, including:</p><ul><li><p>Data Parallel (DP): A legacy approach where data is split across multiple GPUs on a single machine, and model replicas are kept synchronized manually.</p></li><li><p>Collective Communications (c10d): A low-level library providing collective communication primitives (e.g., all-reduce) for synchronizing data across multiple devices and nodes. It supports MPI, NCCL and GLOO backend.</p></li><li><p>Distributed Data Parallel (DDP): The recommended method for scaling training across multiple GPUs and machines, where each process maintains its own model replica and gradient synchronization is performed efficiently using collective communication.</p></li><li><p>Remote Procedure Call (RPC) Framework: A flexible framework enabling model parallelism by allowing different parts of a model to reside and execute on different devices or machines through asynchronous remote execution.</p></li></ul><p>Data parallel is not really a distributed training tool which is discussed in our previous post, we&rsquo;ll not cover it here. In this post, we mainly want to talk about why Torch introduce TorchRPC.</p><h2 id=why-rpc>Why RPC<a hidden class=anchor aria-hidden=true href=#why-rpc>#</a></h2><h3 id=conditional-communication>Conditional Communication<a hidden class=anchor aria-hidden=true href=#conditional-communication>#</a></h3><p>Without RPC (only using p2p communication in <code>torch.distributed</code> .send/.recv), when we want to send tensor y when tensor x is ready from node A to node B, both nodes need to know ahead of time exactly what communication will happen.</p><p>A has tensor x and wants to decide: &ldquo;Should I send tensor y to B or not?&rdquo;
With just .send() and .recv(), both A and B must call these communication functions in matching order ‚Äî otherwise, they will deadlock (e.g., A is sending but B is not receiving, so both get stuck forever). The problem is B cannot &ldquo;wait to see&rdquo; if A wants to send, unless B already knows whether a .recv() is needed. Therefore, B must somehow know what A decided, and in simple .send/.recv world, the only way is to first send x (the condition) to B, so B can evaluate the logic too.</p><h3 id=nodes-communication>Nodes Communication<a hidden class=anchor aria-hidden=true href=#nodes-communication>#</a></h3><p>RPC establishes a p2p communication without requiring <code>init_process_group</code>. For example:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> multiprocessing <span style=color:#66d9ef>as</span> mp
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> torch
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>main</span>(rank,world_size):
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    torch<span style=color:#f92672>.</span>distributed<span style=color:#f92672>.</span>init_process_group(rank<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>,world_size<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>,backend<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;nccl&#39;</span>,init_method<span style=color:#f92672>=</span><span style=color:#e6db74>f</span><span style=color:#e6db74>&#39;tcp://127.0.0.1:</span><span style=color:#e6db74>{</span><span style=color:#ae81ff>29500</span><span style=color:#f92672>+</span>rank<span style=color:#e6db74>}</span><span style=color:#e6db74>&#39;</span>)
</span></span><span style=display:flex><span>    options <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>distributed<span style=color:#f92672>.</span>rpc<span style=color:#f92672>.</span>TensorPipeRpcBackendOptions(init_method<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;tcp://127.0.0.1:30001&#39;</span>)
</span></span><span style=display:flex><span>    torch<span style=color:#f92672>.</span>distributed<span style=color:#f92672>.</span>rpc<span style=color:#f92672>.</span>init_rpc(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#39;worker-</span><span style=color:#e6db74>{</span>rank<span style=color:#e6db74>}</span><span style=color:#e6db74>&#39;</span>, rank<span style=color:#f92672>=</span>rank, world_size<span style=color:#f92672>=</span>world_size, rpc_backend_options<span style=color:#f92672>=</span>options)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#39;rank: </span><span style=color:#e6db74>{</span>torch<span style=color:#f92672>.</span>distributed<span style=color:#f92672>.</span>get_rank()<span style=color:#e6db74>}</span><span style=color:#e6db74>&#39;</span>,
</span></span><span style=display:flex><span>          <span style=color:#e6db74>f</span><span style=color:#e6db74>&#39; world_size: </span><span style=color:#e6db74>{</span>torch<span style=color:#f92672>.</span>distributed<span style=color:#f92672>.</span>get_world_size()<span style=color:#e6db74>}</span><span style=color:#e6db74>&#39;</span>,
</span></span><span style=display:flex><span>          <span style=color:#e6db74>f</span><span style=color:#e6db74>&#39; </span><span style=color:#e6db74>{</span>torch<span style=color:#f92672>.</span>distributed<span style=color:#f92672>.</span>rpc<span style=color:#f92672>.</span>get_worker_info()<span style=color:#e6db74>}</span><span style=color:#e6db74>&#39;</span>)
</span></span><span style=display:flex><span>    torch<span style=color:#f92672>.</span>distributed<span style=color:#f92672>.</span>rpc<span style=color:#f92672>.</span>shutdown()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>if</span> __name__ <span style=color:#f92672>==</span> <span style=color:#e6db74>&#39;__main__&#39;</span>:
</span></span><span style=display:flex><span>    world_size <span style=color:#f92672>=</span> <span style=color:#ae81ff>4</span>
</span></span><span style=display:flex><span>    ps <span style=color:#f92672>=</span> [mp<span style=color:#f92672>.</span>Process(<span style=color:#66d9ef>None</span>,main,args<span style=color:#f92672>=</span>(rank,world_size)) <span style=color:#66d9ef>for</span> rank <span style=color:#f92672>in</span> range(world_size)]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> p <span style=color:#f92672>in</span> ps:
</span></span><span style=display:flex><span>        p<span style=color:#f92672>.</span>start()
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> p <span style=color:#f92672>in</span> ps:
</span></span><span style=display:flex><span>        p<span style=color:#f92672>.</span>join()
</span></span></code></pre></div><table><thead><tr><th></th><th>P2P (.send/.recv)</th><th>RPC</th></tr></thead><tbody><tr><td>Communication</td><td>Must be prearranged on both sides</td><td>Triggered by sender only</td></tr><tr><td>Flexibility</td><td>Low, hard for conditional logic</td><td>High, can easily send conditionally</td></tr><tr><td>Failure mode</td><td>Deadlock if not matching</td><td>No deadlock if only one side triggers</td></tr><tr><td>Best for</td><td>Simple, fixed communication</td><td>Complex, dynamic, conditional logic</td></tr></tbody></table><h2 id=references>References<a hidden class=anchor aria-hidden=true href=#references>#</a></h2><ol><li><a href=https://medium.com/@eeyuhao/pytorch-distributed-a-bottom-up-perspective-e3159ee2c2e7>https://medium.com/@eeyuhao/pytorch-distributed-a-bottom-up-perspective-e3159ee2c2e7</a></li></ol></div><footer class=post-footer><nav class=paginav><a class=prev href=https://rich-junwang.github.io/en-us/posts/tech/llm/speech/whisper/><span class=title>¬´</span><br><span>Whisper Model</span>
</a><a class=next href=https://rich-junwang.github.io/en-us/posts/tech/llm/llm_inference/entropy_decoding/><span class=title>¬ª</span><br><span>Entropy Collapsing in RL Training</span></a></nav></footer></div><style>.comments_details summary::marker{font-size:20px;content:'üëâComment';color:var(--content)}.comments_details[open] summary::marker{font-size:20px;content:'üëáCollapse';color:var(--content)}</style><div><details class=comments_details><summary style="cursor:pointer;margin:50px 0 20px;width:130px"><span style=font-size:20px;color:var(--content)>...</span></summary><div id=tcomment></div></details><script src=https://cdn.staticfile.org/twikoo/1.5.8/twikoo.all.min.js></script><script>twikoo.init({envId:null,el:"#tcomment",lang:"en-us",region:null,path:window.TWIKOO_MAGIC_PATH||window.location.pathname})</script></div></article></main><footer class=footer><span>Copyright
&copy;
2020-2025
<a href=https://rich-junwang.github.io/en-us/ style=color:#939393>Jun's Blog</a>
All Rights Reserved
</span><a href=https://beian.miit.gov.cn/ target=_blank style=color:#939393></a>&nbsp;
<span id=busuanzi_container><span class="fa fa-user"></span> <span id=busuanzi_value_site_uv></span>
<span class="fa fa-eye"></span> <span id=busuanzi_value_site_pv></span></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><span class=topInner><svg class="topSvg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
<span id=read_progress></span>
</span></a><script>document.addEventListener("scroll",function(){const t=document.getElementById("read_progress"),n=document.documentElement.scrollHeight,s=document.documentElement.clientHeight,o=document.documentElement.scrollTop||document.body.scrollTop;t.innerText=((o/(n-s)).toFixed(2)*100).toFixed(0)})</script><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>let mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>200||document.documentElement.scrollTop>200?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{(function(){document.cookie="change-themes="+escape("false")})(),document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.body.addEventListener("copy",function(e){if(window.getSelection().toString()&&window.getSelection().toString().length>50){let t=e.clipboardData||window.clipboardData;if(t){e.preventDefault();let n=window.getSelection().toString()+`\r

‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\r
ÁâàÊùÉÂ£∞ÊòéÔºöÊú¨Êñá‰∏∫„ÄåJun's Blog„ÄçÁöÑÂéüÂàõÊñáÁ´†ÔºåÈÅµÂæ™CC 4.0 BY-SAÁâàÊùÉÂçèËÆÆÔºåËΩ¨ËΩΩËØ∑ÈôÑ‰∏äÂéüÊñáÂá∫Â§ÑÈìæÊé•ÂèäÊú¨Â£∞Êòé„ÄÇ\r
ÂéüÊñáÈìæÊé•Ôºö`+location.href,s=window.getSelection().toString()+`\r

‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\r
ÁâàÊùÉÂ£∞ÊòéÔºöÊú¨Êñá‰∏∫„ÄåJun's Blog„ÄçÁöÑÂéüÂàõÊñáÁ´†ÔºåÈÅµÂæ™CC 4.0 BY-SAÁâàÊùÉÂçèËÆÆÔºåËΩ¨ËΩΩËØ∑ÈôÑ‰∏äÂéüÊñáÂá∫Â§ÑÈìæÊé•ÂèäÊú¨Â£∞Êòé„ÄÇ\r
ÂéüÊñáÈìæÊé•Ôºö`+location.href;t.setData("text/html",n),t.setData("text/plain",s)}}})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const s=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerText="copy";function i(){t.innerText="copied!",setTimeout(()=>{t.innerText="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){let t=e.textContent+`\r
‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\r
ÁâàÊùÉÂ£∞ÊòéÔºöÊú¨Êñá‰∏∫„ÄåJun's Blog„ÄçÁöÑÂéüÂàõÊñáÁ´†ÔºåÈÅµÂæ™CC 4.0 BY-SAÁâàÊùÉÂçèËÆÆÔºåËΩ¨ËΩΩËØ∑ÈôÑ‰∏äÂéüÊñáÂá∫Â§ÑÈìæÊé•ÂèäÊú¨Â£∞Êòé„ÄÇ\r
ÂéüÊñáÈìæÊé•Ôºö`+location.href;navigator.clipboard.writeText(t),i();return}const n=document.createRange();n.selectNodeContents(e);const s=window.getSelection();s.removeAllRanges(),s.addRange(n);try{document.execCommand("copy"),i()}catch{}s.removeRange(n)});let l=e.className.replaceAll("language-",""),n=document.createElement("div"),a=document.createElement("div"),r=document.createElement("div"),c=document.createElement("div"),o=document.createElement("div");o.innerText=l,n.setAttribute("class","mac-tool"),a.setAttribute("class","mac bb1"),r.setAttribute("class","mac bb2"),c.setAttribute("class","mac bb3"),o.setAttribute("class","language-type"),n.appendChild(a),n.appendChild(r),n.appendChild(c),n.appendChild(o),s.classList.contains("highlight")?(s.appendChild(t),s.appendChild(n)):s.parentNode.firstChild==s||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?(e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t),s.appendChild(n)):(e.parentNode.appendChild(t),s.appendChild(n)))})</script></body></html>
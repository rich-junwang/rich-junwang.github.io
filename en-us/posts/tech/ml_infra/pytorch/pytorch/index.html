<!doctype html><html lang=en-us dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Pytorch Multiple-GPU Training | Jun's Blog</title><meta name=keywords content><meta name=description content="PyTorch.."><meta name=author content="Jun"><link rel=canonical href=https://rich-junwang.github.io/en-us/posts/tech/ml_infra/pytorch/pytorch/><link crossorigin=anonymous href=/assets/css/stylesheet.css rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.js onload=hljs.initHighlightingOnLoad()></script><link rel=icon href=https://rich-junwang.github.io/img/Q.gif><link rel=icon type=image/png sizes=16x16 href=https://rich-junwang.github.io/img/Q.gif><link rel=icon type=image/png sizes=32x32 href=https://rich-junwang.github.io/img/Q.gif><link rel=apple-touch-icon href=https://rich-junwang.github.io/img/Q.gif><link rel=mask-icon href=https://rich-junwang.github.io/img/Q.gif><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en-us href=https://rich-junwang.github.io/en-us/posts/tech/ml_infra/pytorch/pytorch/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script defer src=https://unpkg.com/mermaid@8.8.1/dist/mermaid.min.js></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/font-awesome@4.7.0/css/font-awesome.min.css><script src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script><script src=https://cdn.jsdelivr.net/npm/jquery@3.6.3/dist/jquery.min.js></script><script>var _hmt=_hmt||[];(function(){var e,t=document.createElement("script");t.src="",e=document.getElementsByTagName("script")[0],e.parentNode.insertBefore(t,e)})()</script><meta property="og:title" content="Pytorch Multiple-GPU Training"><meta property="og:description" content="PyTorch.."><meta property="og:type" content="article"><meta property="og:url" content="https://rich-junwang.github.io/en-us/posts/tech/ml_infra/pytorch/pytorch/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-06-11T00:18:23+08:00"><meta property="article:modified_time" content="2023-04-11T00:18:23+08:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Pytorch Multiple-GPU Training"><meta name=twitter:description content="PyTorch.."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"üìöArticles","item":"https://rich-junwang.github.io/en-us/posts/"},{"@type":"ListItem","position":2,"name":"üë®üèª‚Äçüíª Tech","item":"https://rich-junwang.github.io/en-us/posts/tech/"},{"@type":"ListItem","position":3,"name":"Pytorch Multiple-GPU Training","item":"https://rich-junwang.github.io/en-us/posts/tech/ml_infra/pytorch/pytorch/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Pytorch Multiple-GPU Training","name":"Pytorch Multiple-GPU Training","description":"PyTorch..","keywords":[""],"articleBody":"Using PyTorch for NN model training on single GPU is simple and easy. However, when it comes to multiple GPU training, there could be various of issues. In this blog, I‚Äôll summarize all kinds of issues I ran into during model training/evaluation.\nGradient Accumulation Gradient accumulation is a way to virtually increase the batch size during training. In gradient accumulation, N batches go through the forward path and backward path, and each time, the gradient is computed and accumulated (usually summed or averaged), but model parameters are not updated. Model parameters are updated after iterate through all N batches. The logic is as follows:\nfor step, oneBatch in enumerate(dataloader): ... ypred = model(oneBatch) loss = loss_func(ytrue, ypred) loss.backward() # release all activations memory if step % accumulation_step == 0: # update weights every accumulation_step steps loss.step() loss.zero_grad() In order to backpropagate, all the hidden activations must be stored until we call loss.backward(). In contrast, if we only add losses together (accumulating losses), all the activation memory won‚Äôt be released, so we can‚Äôt save memory.\nPyTorch Inference At inference time, we call model.eval() so that model wouldn‚Äôt calculate the gradient. It would still be beneficial to wrap the code block with with torch.no_grad(). The reason is it seems PyTorch creates grad buffer for the input tensors created in the computation graph. With this no_grad wrapper, it could free more spaces.\nPyTorch DataParallel DataParallel is very easy to use, we just wrap the model with DataParallel() wrapper. The input should be splittable on dim 0. Caveat here normally when we directly feed output of tokenizer into model, e.g. using tokenizer(input) as model input, this will lead to unsplittable tensors because DP can‚Äôt handle the dictionary there.\nThe issue with DataParallel is unbalanced GPU usage. The input is split to each GPU, and gathered on default GPU (usually cuda:0). Thus, the default GPU has much larger memory load.\nA way to solve this issue is to wrap your model and make sure most ops are done on each GPU. Model only return a small tensor.\nimport torch import torch.nn as nn from torch.utils.data import Dataset, DataLoader input_size = 5 output_size = 2 batch_size = 30 data_size = 100000 device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") class RandomDataset(Dataset): def __init__(self, size, length): self.len = length self.data = torch.randn(length, size) def __getitem__(self, index): return self.data[index] def __len__(self): return self.len rand_loader = DataLoader(dataset=RandomDataset(input_size, data_size), batch_size=batch_size, shuffle=True) class Model(nn.Module): def __init__(self, input_size, output_size): super(Model, self).__init__() self.fc = nn.Linear(input_size, output_size) def forward(self, input): output = self.fc(input) print(\"\\tIn Model: input size\", input.size(), \"output size\", output.size()) return output model = Model(input_size, output_size) if torch.cuda.device_count() \u003e 1: print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\") # dim = 0 [30, xxx] -\u003e [10, ...], [10, ...], [10, ...] on 3 GPUs model = nn.DataParallel(model) model.to(device) for data in rand_loader: input = data.to(device) output = model(input) print(\"Outside: input size\", input.size(), \"output_size\", output.size()) Always make sure that the batch size is divisible by 8. If not, we can do this simple trick. This is helpful when we don‚Äôt use dataloadder and sampler.\n# get smallest number that is greater than x and is multiples of 8 def roundup(x): return (x + 7) \u0026 (-8) if len(input_batch) \u003c batch_size: new_batch_size = roundup(len(input_batch)) input_batch += [input_batch[-1]] * (new_batch_size - len(input_batch)) Install Apex Sometimes to use the latest distributed training feature, we have to install Apex. As Apex is closely coupled with Cuda, we need to follow the next few steps to correctlly install apex.\nFind out the Cuda version used in the system. python -c \"import torch; print(torch.version.cuda)\" Install from source git clone https://github.com/NVIDIA/apex cd apex CUDA_HOME=/usr/local/cuda-{your-version-here}/ pip install -v --disable-pip-version-check --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./ Commonly Used Pytorch Tricks Distributed training is error-prone, so effective ways of debugging is needed. Here I document some of these commands\n# print the whole tensor torch.set_printoptions(profile=\"full\") torch.set_printoptions(linewidth=16000) Dataloader sometimes can be buggy, when there are errors related to dataloader, a good practice is to disable the worker number and disable prefetching.\nLaunch Distributed Run python3 -m torch.distributed.run --nnodes=2 --nproc_per_node 8 --node_rank=${NODE_RANK} --master_port=1234 --master_addr=xxx train.py args.. MASTER_ADDR=${MASTER_ADDR:-\"localhost\"} MASTER_PORT=${MASTER_PORT:-2345} NODE_RANK=${RANK} NNODES=${NUM_NODES} torchrun --nproc-per-node=$GPUS_PER_NODE --nnodes=$NUM_NODES --node_rank $NODE_RANK --rdzv-endpoint=${MASTER_ADDR}:${MASTER_PORT} --rdzv-backend=c10d train.py args.. Pytorch and Numpy Advanced Indexing When selection object is sequence object, ndarray/tensor, it will trigger advanced indexing. To understand how it works, we start from simple.\nx = np.arange(12).reshape(4,3) print(x) #output [[ 0 1 2] [ 3 4 5] [ 6 7 8] [ 9 10 11]] (1) Specify integer arrays in each dimension where every element in the array represents a number of indices into that dimension. In the example below, we select (0, 0), (1, 1), (2, 0) elements from the above array. x has two dimensions so we have two arrays to specify the indices in each dimension.\ny = x[[0,1,2], [0,1,0]] print(y) #[0 4 6] (2) The above way of indexing only renders single dimension result. We can use multi-dimension array to get multi-dimension output. Below is one of these examples. This is to select [(0, 0), (0, 2)], [(3, 0), (3, 2)] elements. Note that in each dimension we still only select one index, like 0 from row-dim, and 0 from col-dim.\nrows = np.array([[0,0],[3,3]]) cols = np.array([[0,2],[0,2]]) y = x[rows,cols] print (y) # output [[ 0 2] [ 9 11]] Loading a pretrained checkpoint A lot of times when we save a checkpoint of a pretrained model, we also save the trainer (or model state) information. This means when we load model checkpoint again, model will already have a preallocated device. When we use the same number of GPU to continue training, it will work as expected. However, the issue will arise when we have different number of GPUs for two runs. Let‚Äôs say, we first trained model on a single GPU, then we want to use multiple GPU to continue the training. When we move model to multiple GPU, there will be something weird. For instance, on GPU 0, you might see multiple process (normally one process per GPU). Or in other cases, you can see GPU 0 has much higher memory usage than other GPUs.\nSolution: when we load model, we only load parameters and strip all state information. This might be tricky sometimes. The simplest way to solve this issue is to wrap the command with with PyTorch distributed data parallel.\npython3 -m torch.distributed.launch --nnodes=1 --nproc_per_node=8 my_script.py my_config_file Nvidia Issues CUDA initialization: Unexpected error from cudaGetDeviceCount() This issue arises because ubuntu system update leads to nvidia-fabricmanager update, which leads the version mismatch between cuda driver and nvidia-fabricmanager.\nCheck nvidia fabric package status:\nsystemctl status nvidia-fabricmanager # or the following command journalctl -u nvidia-fabricmanager.service My solution is to install the latest cuda driver and latest nvidia-fabricmanager. Below I just show how to install the latest nvidia-fabricmanager.\n# purge old version sudo apt remove nvidia-fabricmanager-* # download latest version, note that # - don't download cuda-driver-fabricmanager-xxx # - don't download the dev version wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/nvidia-fabricmanager-575_575.51.03-1_amd64.deb sudo dpkg -i ./nvidia-fabricmanager-575_575.51.03-1_amd64.deb # if there is issue sudo apt --fix-broken install # re-enable the service sudo systemctl enable nvidia-fabricmanager sudo systemctl restart nvidia-fabricmanager If getting the error Failed to enable unit: Unit file /etc/systemd/system/nvidia-fabricmanager.service is masked, we can do\nsudo systemctl unmask nvidia-fabricmanager.service # or sudo rm /etc/systemd/system/nvidia-fabricmanager.service sudo rm /lib/systemd/system/nvidia-fabricmanager.service Then reinstall the fabric manager package. Using the following command to verify the installation.\npython -c \"import torch ; print(torch.cuda.device_count())\" When installing nvidia driver has issue such as NVIDIA kernel module appears to already be loaded in your kernel. This may be because it's in use. Use the following to fix this issue\n# check nvidia.drm lsmod | grep nvidia.drm # unload nvidia-drm sudo modprobe -r nvidia-drm sudo systemctl isolate multi-user.target sudo systemctl set-default multi-user.target sudo apt purge nvidia-* sudo apt autoremove sudo reboot ","wordCount":"1285","inLanguage":"en-us","datePublished":"2022-06-11T00:18:23+08:00","dateModified":"2023-04-11T00:18:23+08:00","author":[{"@type":"Person","name":"Jun"}],"mainEntityOfPage":{"@type":"WebPage","@id":"https://rich-junwang.github.io/en-us/posts/tech/ml_infra/pytorch/pytorch/"},"publisher":{"@type":"Organization","name":"Jun's Blog","logo":{"@type":"ImageObject","url":"https://rich-junwang.github.io/img/Q.gif"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://rich-junwang.github.io/en-us/ accesskey=h title="Jun's Blog (Alt + H)"><img src=https://rich-junwang.github.io/img/Q.gif alt=logo aria-label=logo height=35>Jun's Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)">
<svg id="moon" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li></ul></div></div><ul id=menu><li><a href=https://rich-junwang.github.io/en-us/ title="üè† Home"><span>üè† Home</span></a></li><li><a href=https://rich-junwang.github.io/en-us/about title="üôãüèª‚Äç‚ôÇÔ∏è About"><span>üôãüèª‚Äç‚ôÇÔ∏è About</span></a></li><li><a href=https://rich-junwang.github.io/en-us/posts title="üìö Posts"><span>üìö Posts</span></a></li><li><a href=https://rich-junwang.github.io/en-us/tags title="üß© Tags"><span>üß© Tags</span></a></li><li><a href=https://rich-junwang.github.io/en-us/archives/ title="‚è±Ô∏è Archives"><span>‚è±Ô∏è Archives</span></a></li><li><a href=https://rich-junwang.github.io/en-us/search title="üîç Search (Alt + /)" accesskey=/><span>üîç Search</span></a></li></ul></nav></header><main class="main page"><style>i[id*=post_meta_style]{display:flex;align-items:center;margin:0 0 10px}</style><article class=post-single><div id=single-content><header class=post-header><div class=breadcrumbs><a href=https://rich-junwang.github.io/en-us/>üè† Home</a>&nbsp;¬ª&nbsp;<a href=https://rich-junwang.github.io/en-us/posts/>üìöArticles</a>&nbsp;¬ª&nbsp;<a href=https://rich-junwang.github.io/en-us/posts/tech/>üë®üèª‚Äçüíª Tech</a></div><h1 class=post-title>Pytorch Multiple-GPU Training</h1><div class=post-description>PyTorch..</div><div class=post-meta><style>i[id*=post_meta_style]{display:flex;align-items:center;margin:0 0 10px}.parent-post-meta{display:flex;flex-wrap:wrap;opacity:.8}</style><span class=parent-post-meta><span id=post_meta_style_1><span class="fa fa-calendar-check-o"></span>
<span>2022-06-11
&nbsp;&nbsp;
</span></span><span id=post_meta_style_3><span class="fa fa-file-word-o"></span>
<span>1285 words
&nbsp;&nbsp;
</span></span><span id=post_meta_style_4><span class="fa fa-clock-o"></span>
<span>3 min
&nbsp;&nbsp;
</span></span><span id=post_meta_style_5><span class="fa fa-user-o"></span>
<span>Jun
&nbsp;&nbsp;
</span></span><span id=post_meta_style_6><span class="fa fa-tags" style=opacity:.8></span>
<span><span class=post-tags-meta><a href=https://rich-junwang.github.io/en-us/tags/blog/ style="color:var(--secondary) !important">Blog</a>
</span></span></span></span><span style=opacity:.8><span id=post_meta_style_7>&nbsp;&nbsp;
<span class="fa fa-eye"></span>
<span><span id=busuanzi_container_page_pv><span id=busuanzi_value_page_pv></span></span>
&nbsp;&nbsp;
</span></span><span id=post_meta_style_8><span class="fa fa-commenting-o"></span>
<span><script src=https://cdn.staticfile.org/twikoo/1.5.8/twikoo.all.min.js></script><script>let url=document.documentURI,dnsUrl="https://rich-junwang.github.io/",urlSplit=url.split(dnsUrl),finalUrl=urlSplit[1];finalUrl[0]!=="/"&&(finalUrl="/"+finalUrl),twikoo.getCommentsCount({envId:null,region:null,urls:[finalUrl],includeReply:!1}).then(function(e){let t=e[0].count;const n=document.getElementById("comment_count");n.innerText=t}).catch(function(e){console.error(e)})</script><span id=comment_count></span></span></span></span></div></header><aside id=toc-container class="toc-container wide"><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#gradient-accumulation aria-label="Gradient Accumulation">Gradient Accumulation</a></li><li><a href=#pytorch-inference aria-label="PyTorch Inference">PyTorch Inference</a></li><li><a href=#pytorch-dataparallel aria-label="PyTorch DataParallel">PyTorch DataParallel</a></li><li><a href=#install-apex aria-label="Install Apex">Install Apex</a><ul><li><a href=#commonly-used-pytorch-tricks aria-label="Commonly Used Pytorch Tricks">Commonly Used Pytorch Tricks</a></li></ul></li><li><a href=#launch-distributed-run aria-label="Launch Distributed Run">Launch Distributed Run</a></li><li><a href=#pytorch-and-numpy-advanced-indexing aria-label="Pytorch and Numpy Advanced Indexing">Pytorch and Numpy Advanced Indexing</a></li><li><a href=#loading-a-pretrained-checkpoint aria-label="Loading a pretrained checkpoint">Loading a pretrained checkpoint</a></li><li><a href=#nvidia-issues aria-label="Nvidia Issues">Nvidia Issues</a></li></ul></div></details></div></aside><script>let activeElement,elements;window.addEventListener("DOMContentLoaded",function(){checkTocPosition(),elements=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]"),activeElement=elements[0];const t=encodeURI(activeElement.getAttribute("id")).toLowerCase();document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active")},!1),window.addEventListener("resize",function(){checkTocPosition()},!1),window.addEventListener("scroll",()=>{elements&&(activeElement=Array.from(elements).find(e=>{if(getOffsetTop(e)-window.pageYOffset>0&&getOffsetTop(e)-window.pageYOffset<window.innerHeight/2)return e})||activeElement,elements.forEach(e=>{const t=encodeURI(e.getAttribute("id")).toLowerCase();e===activeElement?document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active"):document.querySelector(`.inner ul li a[href="#${t}"]`).classList.remove("active")}))},!1);const main=parseInt(getComputedStyle(document.body).getPropertyValue("--article-width"),10),toc=parseInt(getComputedStyle(document.body).getPropertyValue("--toc-width"),10),gap=parseInt(getComputedStyle(document.body).getPropertyValue("--gap"),10);function checkTocPosition(){const e=document.body.scrollWidth;e-main-toc*2-gap*4>0?document.getElementById("toc-container").classList.add("wide"):document.getElementById("toc-container").classList.remove("wide")}function getOffsetTop(e){if(!e.getClientRects().length)return 0;let t=e.getBoundingClientRect(),n=e.ownerDocument.defaultView;return t.top+n.pageYOffset}</script><div class=post-content><p>Using PyTorch for NN model training on single GPU is simple and easy. However, when it comes to multiple GPU training, there could be various of issues. In this blog, I&rsquo;ll summarize all kinds of issues I ran into during model training/evaluation.</p><h2 id=gradient-accumulation>Gradient Accumulation<a hidden class=anchor aria-hidden=true href=#gradient-accumulation>#</a></h2><p>Gradient accumulation is a way to virtually increase the batch size during training. In gradient accumulation, <code>N</code> batches go through the forward path and backward path, and each time, the gradient is computed and accumulated (usually summed or averaged), but model parameters are not updated. Model parameters are updated after iterate through all <code>N</code> batches. The logic is as follows:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-gdscript3 data-lang=gdscript3><span style=display:flex><span><span style=color:#66d9ef>for</span> step, oneBatch <span style=color:#f92672>in</span> enumerate(dataloader):
</span></span><span style=display:flex><span>   <span style=color:#f92672>...</span> 
</span></span><span style=display:flex><span>   ypred <span style=color:#f92672>=</span> model(oneBatch)
</span></span><span style=display:flex><span>   loss <span style=color:#f92672>=</span> loss_func(ytrue, ypred)
</span></span><span style=display:flex><span>   loss<span style=color:#f92672>.</span>backward() <span style=color:#75715e># release all activations memory</span>
</span></span><span style=display:flex><span>   <span style=color:#66d9ef>if</span> step <span style=color:#f92672>%</span> accumulation_step <span style=color:#f92672>==</span> <span style=color:#ae81ff>0</span>: 
</span></span><span style=display:flex><span>      <span style=color:#75715e># update weights every accumulation_step steps</span>
</span></span><span style=display:flex><span>      loss<span style=color:#f92672>.</span>step() 
</span></span><span style=display:flex><span>      loss<span style=color:#f92672>.</span>zero_grad()
</span></span></code></pre></div><p>In order to backpropagate, all the hidden activations must be stored until we call loss.backward(). In contrast, if we only add losses together (accumulating losses), all the activation memory won&rsquo;t be released, so we can&rsquo;t save memory.</p><h2 id=pytorch-inference>PyTorch Inference<a hidden class=anchor aria-hidden=true href=#pytorch-inference>#</a></h2><p>At inference time, we call <code>model.eval()</code> so that model wouldn&rsquo;t calculate the gradient. It would still be beneficial to wrap the code block with <code>with torch.no_grad()</code>. The reason is it seems PyTorch creates grad buffer for the input tensors created in the computation graph. With this no_grad wrapper, it could free more spaces.</p><h2 id=pytorch-dataparallel>PyTorch DataParallel<a hidden class=anchor aria-hidden=true href=#pytorch-dataparallel>#</a></h2><p>DataParallel is very easy to use, we just wrap the model with <code>DataParallel()</code> wrapper. The input should be splittable on dim 0. Caveat here normally when we directly feed output of tokenizer into model, e.g. using <code>tokenizer(input)</code> as model input, this will lead to unsplittable tensors because DP can&rsquo;t handle the dictionary there.</p><p>The issue with <code>DataParallel</code> is unbalanced GPU usage. The input is split to each GPU, and gathered on default GPU (usually cuda:0). Thus, the default GPU has much larger memory load.</p><p>A way to solve this issue is to wrap your model and make sure most ops are done on each GPU. Model only return a small tensor.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> torch
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> torch.nn <span style=color:#66d9ef>as</span> nn
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> torch.utils.data <span style=color:#f92672>import</span> Dataset, DataLoader
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>input_size <span style=color:#f92672>=</span> <span style=color:#ae81ff>5</span>
</span></span><span style=display:flex><span>output_size <span style=color:#f92672>=</span> <span style=color:#ae81ff>2</span>
</span></span><span style=display:flex><span>batch_size <span style=color:#f92672>=</span> <span style=color:#ae81ff>30</span>
</span></span><span style=display:flex><span>data_size <span style=color:#f92672>=</span> <span style=color:#ae81ff>100000</span>
</span></span><span style=display:flex><span>device <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>device(<span style=color:#e6db74>&#34;cuda:0&#34;</span> <span style=color:#66d9ef>if</span> torch<span style=color:#f92672>.</span>cuda<span style=color:#f92672>.</span>is_available() <span style=color:#66d9ef>else</span> <span style=color:#e6db74>&#34;cpu&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>RandomDataset</span>(Dataset):
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>__init__</span>(self, size, length):
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>len <span style=color:#f92672>=</span> length
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>data <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>randn(length, size)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>__getitem__</span>(self, index):
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> self<span style=color:#f92672>.</span>data[index]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>__len__</span>(self):
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> self<span style=color:#f92672>.</span>len
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>rand_loader <span style=color:#f92672>=</span> DataLoader(dataset<span style=color:#f92672>=</span>RandomDataset(input_size, data_size),
</span></span><span style=display:flex><span>                         batch_size<span style=color:#f92672>=</span>batch_size, shuffle<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>Model</span>(nn<span style=color:#f92672>.</span>Module):
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>__init__</span>(self, input_size, output_size):
</span></span><span style=display:flex><span>        super(Model, self)<span style=color:#f92672>.</span><span style=color:#a6e22e>__init__</span>()
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>fc <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Linear(input_size, output_size)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>forward</span>(self, input):
</span></span><span style=display:flex><span>        output <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>fc(input)
</span></span><span style=display:flex><span>        print(<span style=color:#e6db74>&#34;</span><span style=color:#ae81ff>\t</span><span style=color:#e6db74>In Model: input size&#34;</span>, input<span style=color:#f92672>.</span>size(),
</span></span><span style=display:flex><span>              <span style=color:#e6db74>&#34;output size&#34;</span>, output<span style=color:#f92672>.</span>size())
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> output
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>model <span style=color:#f92672>=</span> Model(input_size, output_size)
</span></span><span style=display:flex><span><span style=color:#66d9ef>if</span> torch<span style=color:#f92672>.</span>cuda<span style=color:#f92672>.</span>device_count() <span style=color:#f92672>&gt;</span> <span style=color:#ae81ff>1</span>:
</span></span><span style=display:flex><span>  print(<span style=color:#e6db74>&#34;Let&#39;s use&#34;</span>, torch<span style=color:#f92672>.</span>cuda<span style=color:#f92672>.</span>device_count(), <span style=color:#e6db74>&#34;GPUs!&#34;</span>)
</span></span><span style=display:flex><span>  <span style=color:#75715e># dim = 0 [30, xxx] -&gt; [10, ...], [10, ...], [10, ...] on 3 GPUs</span>
</span></span><span style=display:flex><span>  model <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>DataParallel(model)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>model<span style=color:#f92672>.</span>to(device)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> data <span style=color:#f92672>in</span> rand_loader:
</span></span><span style=display:flex><span>    input <span style=color:#f92672>=</span> data<span style=color:#f92672>.</span>to(device)
</span></span><span style=display:flex><span>    output <span style=color:#f92672>=</span> model(input)
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>&#34;Outside: input size&#34;</span>, input<span style=color:#f92672>.</span>size(),
</span></span><span style=display:flex><span>          <span style=color:#e6db74>&#34;output_size&#34;</span>, output<span style=color:#f92672>.</span>size())
</span></span></code></pre></div><p>Always make sure that the batch size is divisible by 8. If not, we can do this simple trick. This is helpful when we don&rsquo;t use dataloadder and sampler.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># get smallest number that is greater than x and is multiples of 8</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>roundup</span>(x):
</span></span><span style=display:flex><span>   <span style=color:#66d9ef>return</span> (x <span style=color:#f92672>+</span> <span style=color:#ae81ff>7</span>) <span style=color:#f92672>&amp;</span> (<span style=color:#f92672>-</span><span style=color:#ae81ff>8</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>if</span> len(input_batch) <span style=color:#f92672>&lt;</span> batch_size:
</span></span><span style=display:flex><span>   new_batch_size <span style=color:#f92672>=</span> roundup(len(input_batch))
</span></span><span style=display:flex><span>   input_batch <span style=color:#f92672>+=</span> [input_batch[<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>]] <span style=color:#f92672>*</span> (new_batch_size <span style=color:#f92672>-</span> len(input_batch))
</span></span></code></pre></div><h2 id=install-apex>Install Apex<a hidden class=anchor aria-hidden=true href=#install-apex>#</a></h2><p>Sometimes to use the latest distributed training feature, we have to install Apex. As Apex is closely coupled with Cuda, we need to follow the next few steps to correctlly install apex.</p><ul><li>Find out the Cuda version used in the system.</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>python -c &#34;import torch; print(torch.version.cuda)&#34;
</span></span></code></pre></div><ul><li>Install from source</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>git clone https://github.com/NVIDIA/apex
</span></span><span style=display:flex><span>cd apex
</span></span><span style=display:flex><span>CUDA_HOME=/usr/local/cuda-{your-version-here}/ pip install -v --disable-pip-version-check --no-cache-dir --global-option=&#34;--cpp_ext&#34; --global-option=&#34;--cuda_ext&#34; ./
</span></span></code></pre></div><h3 id=commonly-used-pytorch-tricks>Commonly Used Pytorch Tricks<a hidden class=anchor aria-hidden=true href=#commonly-used-pytorch-tricks>#</a></h3><p>Distributed training is error-prone, so effective ways of debugging is needed. Here I document some of these commands</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span># print the whole tensor
</span></span><span style=display:flex><span>torch.set_printoptions(profile=&#34;full&#34;)
</span></span><span style=display:flex><span>torch.set_printoptions(linewidth=16000)
</span></span></code></pre></div><p>Dataloader sometimes can be buggy, when there are errors related to dataloader, a good practice is to disable the worker number and disable prefetching.</p><h2 id=launch-distributed-run>Launch Distributed Run<a hidden class=anchor aria-hidden=true href=#launch-distributed-run>#</a></h2><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>python3 -m torch.distributed.run --nnodes<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span> --nproc_per_node <span style=color:#ae81ff>8</span> --node_rank<span style=color:#f92672>=</span><span style=color:#e6db74>${</span>NODE_RANK<span style=color:#e6db74>}</span> --master_port<span style=color:#f92672>=</span><span style=color:#ae81ff>1234</span> --master_addr<span style=color:#f92672>=</span>xxx train.py args..
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>MASTER_ADDR<span style=color:#f92672>=</span><span style=color:#e6db74>${</span>MASTER_ADDR<span style=color:#66d9ef>:-</span><span style=color:#e6db74>&#34;localhost&#34;</span><span style=color:#e6db74>}</span>
</span></span><span style=display:flex><span>MASTER_PORT<span style=color:#f92672>=</span><span style=color:#e6db74>${</span>MASTER_PORT<span style=color:#66d9ef>:-</span>2345<span style=color:#e6db74>}</span>
</span></span><span style=display:flex><span>NODE_RANK<span style=color:#f92672>=</span><span style=color:#e6db74>${</span>RANK<span style=color:#e6db74>}</span>
</span></span><span style=display:flex><span>NNODES<span style=color:#f92672>=</span><span style=color:#e6db74>${</span>NUM_NODES<span style=color:#e6db74>}</span>
</span></span><span style=display:flex><span>torchrun  --nproc-per-node<span style=color:#f92672>=</span>$GPUS_PER_NODE --nnodes<span style=color:#f92672>=</span>$NUM_NODES --node_rank $NODE_RANK  --rdzv-endpoint<span style=color:#f92672>=</span><span style=color:#e6db74>${</span>MASTER_ADDR<span style=color:#e6db74>}</span>:<span style=color:#e6db74>${</span>MASTER_PORT<span style=color:#e6db74>}</span>  --rdzv-backend<span style=color:#f92672>=</span>c10d train.py args..
</span></span></code></pre></div><h2 id=pytorch-and-numpy-advanced-indexing>Pytorch and Numpy Advanced Indexing<a hidden class=anchor aria-hidden=true href=#pytorch-and-numpy-advanced-indexing>#</a></h2><p>When selection object is sequence object, ndarray/tensor, it will trigger advanced indexing. To understand how it works, we start from simple.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>x <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>arange(<span style=color:#ae81ff>12</span>)<span style=color:#f92672>.</span>reshape(<span style=color:#ae81ff>4</span>,<span style=color:#ae81ff>3</span>)
</span></span><span style=display:flex><span>print(x)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>#output</span>
</span></span><span style=display:flex><span>[[ <span style=color:#ae81ff>0</span>  <span style=color:#ae81ff>1</span>  <span style=color:#ae81ff>2</span>]
</span></span><span style=display:flex><span> [ <span style=color:#ae81ff>3</span>  <span style=color:#ae81ff>4</span>  <span style=color:#ae81ff>5</span>]
</span></span><span style=display:flex><span> [ <span style=color:#ae81ff>6</span>  <span style=color:#ae81ff>7</span>  <span style=color:#ae81ff>8</span>]
</span></span><span style=display:flex><span> [ <span style=color:#ae81ff>9</span> <span style=color:#ae81ff>10</span> <span style=color:#ae81ff>11</span>]]
</span></span></code></pre></div><p>(1) Specify integer arrays in each dimension where every element in the array represents a number of indices into that dimension. In the example below, we select (0, 0), (1, 1), (2, 0) elements from the above array. <code>x</code> has two dimensions so we have two arrays to specify the indices in each dimension.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>y = x[[0,1,2],  [0,1,0]]
</span></span><span style=display:flex><span>print(y) 
</span></span><span style=display:flex><span>#[0 4 6]
</span></span></code></pre></div><p>(2) The above way of indexing only renders single dimension result. We can use multi-dimension array to get multi-dimension output. Below is one of these examples. This is to select [(0, 0), (0, 2)], [(3, 0), (3, 2)] elements. Note that in each dimension we still only select one index, like 0 from row-dim, and 0 from col-dim.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>rows = np.array([[0,0],[3,3]]) 
</span></span><span style=display:flex><span>cols = np.array([[0,2],[0,2]])
</span></span><span style=display:flex><span>y = x[rows,cols]  
</span></span><span style=display:flex><span>print (y)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span># output
</span></span><span style=display:flex><span>[[ 0  2]
</span></span><span style=display:flex><span> [ 9 11]]
</span></span></code></pre></div><h2 id=loading-a-pretrained-checkpoint>Loading a pretrained checkpoint<a hidden class=anchor aria-hidden=true href=#loading-a-pretrained-checkpoint>#</a></h2><p>A lot of times when we save a checkpoint of a pretrained model, we also save the trainer (or model state) information. This means when we load model checkpoint again, model will already have a preallocated device. When we use the same number of GPU to continue training, it will work as expected. However, the issue will arise when we have different number of GPUs for two runs. Let&rsquo;s say, we first trained model on a single GPU, then we want to use multiple GPU to continue the training. When we move model to multiple GPU, there will be something weird. For instance, on GPU 0, you might see multiple process (normally one process per GPU). Or in other cases, you can see GPU 0 has much higher memory usage than other GPUs.</p><p>Solution: when we load model, we only load parameters and strip all state information. This might be tricky sometimes. The simplest way to solve this issue is to wrap the command with with PyTorch distributed data parallel.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>python3 -m torch.distributed.launch --nnodes=1 --nproc_per_node=8 my_script.py my_config_file 
</span></span></code></pre></div><h2 id=nvidia-issues>Nvidia Issues<a hidden class=anchor aria-hidden=true href=#nvidia-issues>#</a></h2><ol><li>CUDA initialization: Unexpected error from cudaGetDeviceCount()</li></ol><p>This issue arises because ubuntu system update leads to nvidia-fabricmanager update, which leads the version mismatch between cuda driver and nvidia-fabricmanager.</p><p>Check nvidia fabric package status:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>systemctl status nvidia-fabricmanager
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># or the following command</span>
</span></span><span style=display:flex><span>journalctl -u nvidia-fabricmanager.service
</span></span></code></pre></div><p>My solution is to install the latest cuda driver and latest nvidia-fabricmanager. Below I just show how to install the latest nvidia-fabricmanager.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># purge old version</span>
</span></span><span style=display:flex><span>sudo apt remove nvidia-fabricmanager-*
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># download latest version, note that</span>
</span></span><span style=display:flex><span><span style=color:#75715e># - don&#39;t download cuda-driver-fabricmanager-xxx</span>
</span></span><span style=display:flex><span><span style=color:#75715e># - don&#39;t download the dev version</span>
</span></span><span style=display:flex><span>wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/nvidia-fabricmanager-575_575.51.03-1_amd64.deb
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>sudo dpkg -i ./nvidia-fabricmanager-575_575.51.03-1_amd64.deb
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># if there is issue</span>
</span></span><span style=display:flex><span>sudo apt --fix-broken install
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># re-enable the service</span>
</span></span><span style=display:flex><span>sudo systemctl enable nvidia-fabricmanager
</span></span><span style=display:flex><span>sudo systemctl restart nvidia-fabricmanager
</span></span></code></pre></div><p>If getting the error <code>Failed to enable unit: Unit file /etc/systemd/system/nvidia-fabricmanager.service is masked</code>,
we can do</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>sudo systemctl unmask nvidia-fabricmanager.service
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># or</span>
</span></span><span style=display:flex><span>sudo rm /etc/systemd/system/nvidia-fabricmanager.service
</span></span><span style=display:flex><span>sudo rm /lib/systemd/system/nvidia-fabricmanager.service
</span></span></code></pre></div><p>Then reinstall the fabric manager package. Using the following command to verify the installation.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>python -c <span style=color:#e6db74>&#34;import torch ; print(torch.cuda.device_count())&#34;</span>
</span></span></code></pre></div><p>When installing nvidia driver has issue such as <code>NVIDIA kernel module appears to already be loaded in your kernel. This may be because it's in use</code>. Use the following to fix this issue</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># check nvidia.drm</span>
</span></span><span style=display:flex><span>lsmod | grep nvidia.drm
</span></span><span style=display:flex><span><span style=color:#75715e># unload nvidia-drm</span>
</span></span><span style=display:flex><span>sudo modprobe -r nvidia-drm
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>sudo systemctl isolate multi-user.target
</span></span><span style=display:flex><span>sudo systemctl set-default multi-user.target
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>sudo apt purge nvidia-*
</span></span><span style=display:flex><span>sudo apt autoremove
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>sudo reboot
</span></span></code></pre></div></div><footer class=post-footer><nav class=paginav><a class=prev href=https://rich-junwang.github.io/en-us/posts/tech/ml_infra/parallelism/><span class=title>¬´</span><br><span>Parallelism in LLM Training</span>
</a><a class=next href=https://rich-junwang.github.io/en-us/posts/tech/ml_infra/distributed_train_infra/><span class=title>¬ª</span><br><span>Distributed Training Infra</span></a></nav></footer></div><style>.comments_details summary::marker{font-size:20px;content:'üëâComment';color:var(--content)}.comments_details[open] summary::marker{font-size:20px;content:'üëáCollapse';color:var(--content)}</style><div><details class=comments_details><summary style="cursor:pointer;margin:50px 0 20px;width:130px"><span style=font-size:20px;color:var(--content)>...</span></summary><div id=tcomment></div></details><script src=https://cdn.staticfile.org/twikoo/1.5.8/twikoo.all.min.js></script><script>twikoo.init({envId:null,el:"#tcomment",lang:"en-us",region:null,path:window.TWIKOO_MAGIC_PATH||window.location.pathname})</script></div></article></main><footer class=footer><span>Copyright
&copy;
2020-2025
<a href=https://rich-junwang.github.io/en-us/ style=color:#939393>Jun's Blog</a>
All Rights Reserved
</span><a href=https://beian.miit.gov.cn/ target=_blank style=color:#939393></a>&nbsp;
<span id=busuanzi_container><span class="fa fa-user"></span> <span id=busuanzi_value_site_uv></span>
<span class="fa fa-eye"></span> <span id=busuanzi_value_site_pv></span></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><span class=topInner><svg class="topSvg" viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
<span id=read_progress></span>
</span></a><script>document.addEventListener("scroll",function(){const t=document.getElementById("read_progress"),n=document.documentElement.scrollHeight,s=document.documentElement.clientHeight,o=document.documentElement.scrollTop||document.body.scrollTop;t.innerText=((o/(n-s)).toFixed(2)*100).toFixed(0)})</script><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>let mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>200||document.documentElement.scrollTop>200?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{(function(){document.cookie="change-themes="+escape("false")})(),document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.body.addEventListener("copy",function(e){if(window.getSelection().toString()&&window.getSelection().toString().length>50){let t=e.clipboardData||window.clipboardData;if(t){e.preventDefault();let n=window.getSelection().toString()+`\r

‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\r
ÁâàÊùÉÂ£∞ÊòéÔºöÊú¨Êñá‰∏∫„ÄåJun's Blog„ÄçÁöÑÂéüÂàõÊñáÁ´†ÔºåÈÅµÂæ™CC 4.0 BY-SAÁâàÊùÉÂçèËÆÆÔºåËΩ¨ËΩΩËØ∑ÈôÑ‰∏äÂéüÊñáÂá∫Â§ÑÈìæÊé•ÂèäÊú¨Â£∞Êòé„ÄÇ\r
ÂéüÊñáÈìæÊé•Ôºö`+location.href,s=window.getSelection().toString()+`\r

‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\r
ÁâàÊùÉÂ£∞ÊòéÔºöÊú¨Êñá‰∏∫„ÄåJun's Blog„ÄçÁöÑÂéüÂàõÊñáÁ´†ÔºåÈÅµÂæ™CC 4.0 BY-SAÁâàÊùÉÂçèËÆÆÔºåËΩ¨ËΩΩËØ∑ÈôÑ‰∏äÂéüÊñáÂá∫Â§ÑÈìæÊé•ÂèäÊú¨Â£∞Êòé„ÄÇ\r
ÂéüÊñáÈìæÊé•Ôºö`+location.href;t.setData("text/html",n),t.setData("text/plain",s)}}})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const s=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerText="copy";function i(){t.innerText="copied!",setTimeout(()=>{t.innerText="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){let t=e.textContent+`\r
‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\r
ÁâàÊùÉÂ£∞ÊòéÔºöÊú¨Êñá‰∏∫„ÄåJun's Blog„ÄçÁöÑÂéüÂàõÊñáÁ´†ÔºåÈÅµÂæ™CC 4.0 BY-SAÁâàÊùÉÂçèËÆÆÔºåËΩ¨ËΩΩËØ∑ÈôÑ‰∏äÂéüÊñáÂá∫Â§ÑÈìæÊé•ÂèäÊú¨Â£∞Êòé„ÄÇ\r
ÂéüÊñáÈìæÊé•Ôºö`+location.href;navigator.clipboard.writeText(t),i();return}const n=document.createRange();n.selectNodeContents(e);const s=window.getSelection();s.removeAllRanges(),s.addRange(n);try{document.execCommand("copy"),i()}catch{}s.removeRange(n)});let l=e.className.replaceAll("language-",""),n=document.createElement("div"),a=document.createElement("div"),r=document.createElement("div"),c=document.createElement("div"),o=document.createElement("div");o.innerText=l,n.setAttribute("class","mac-tool"),a.setAttribute("class","mac bb1"),r.setAttribute("class","mac bb2"),c.setAttribute("class","mac bb3"),o.setAttribute("class","language-type"),n.appendChild(a),n.appendChild(r),n.appendChild(c),n.appendChild(o),s.classList.contains("highlight")?(s.appendChild(t),s.appendChild(n)):s.parentNode.firstChild==s||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?(e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t),s.appendChild(n)):(e.parentNode.appendChild(t),s.appendChild(n)))})</script></body></html>
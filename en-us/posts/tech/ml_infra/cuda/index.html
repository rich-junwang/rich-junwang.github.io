<!doctype html><html lang=en-us dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>CUDA | Jun's Blog</title>
<meta name=keywords content><meta name=description content="CUDA"><meta name=author content="Jun"><link rel=canonical href=https://rich-junwang.github.io/en-us/posts/tech/ml_infra/cuda/><link crossorigin=anonymous href=/assets/css/stylesheet.css rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.js onload=hljs.initHighlightingOnLoad()></script><link rel=icon href=https://rich-junwang.github.io/img/Q.gif><link rel=icon type=image/png sizes=16x16 href=https://rich-junwang.github.io/img/Q.gif><link rel=icon type=image/png sizes=32x32 href=https://rich-junwang.github.io/img/Q.gif><link rel=apple-touch-icon href=https://rich-junwang.github.io/img/Q.gif><link rel=mask-icon href=https://rich-junwang.github.io/img/Q.gif><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en-us href=https://rich-junwang.github.io/en-us/posts/tech/ml_infra/cuda/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script defer src=https://unpkg.com/mermaid@8.8.1/dist/mermaid.min.js></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/font-awesome@4.7.0/css/font-awesome.min.css><script src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script><script src=https://cdn.jsdelivr.net/npm/jquery@3.6.3/dist/jquery.min.js></script><script>var _hmt=_hmt||[];(function(){var e,t=document.createElement("script");t.src="",e=document.getElementsByTagName("script")[0],e.parentNode.insertBefore(t,e)})()</script><meta property="og:title" content="CUDA"><meta property="og:description" content="CUDA"><meta property="og:type" content="article"><meta property="og:url" content="https://rich-junwang.github.io/en-us/posts/tech/ml_infra/cuda/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-05-05T00:18:23+08:00"><meta property="article:modified_time" content="2023-05-05T00:18:23+08:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="CUDA"><meta name=twitter:description content="CUDA"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"ğŸ“šArticles","item":"https://rich-junwang.github.io/en-us/posts/"},{"@type":"ListItem","position":2,"name":"ğŸ‘¨ğŸ»â€ğŸ’» Tech","item":"https://rich-junwang.github.io/en-us/posts/tech/"},{"@type":"ListItem","position":3,"name":"CUDA","item":"https://rich-junwang.github.io/en-us/posts/tech/ml_infra/cuda/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"CUDA","name":"CUDA","description":"CUDA","keywords":[""],"articleBody":"CUDA Ecosystem CUDA Toolkit (Libraries and Compiler) The CUDA Toolkit contains the NVCC compiler and the development libraries (like cuBLAS, cuDNN, and the core CUDA libraries). Those libraries build on top of runtime API to save developers from writing complex, performance-critical algorithms from scratch.\nCUDA Toolkit Installation\nGo to the link here. It will guide you to the following instructions. Note that select the cuda-toolkit version lower than the cuda driver version (from nvidia-smi).\nwget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2404/x86_64/cuda-keyring_1.1-1_all.deb sudo dpkg -i cuda-keyring_1.1-1_all.deb sudo apt-get update sudo apt-get -y install cuda-toolkit-13-0 After the installation, adding the binary path into your PATH\nexport PATH=${PATH}:/usr/local/cuda/bin export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/usr/local/cuda/lib64 Check installation,\nnvcc --version If we have multiple cuda installed, we can use the following command to choose the default one\nsudo update-alternatives --display cuda # If CUDA 12.8 is not listed as an option, add it: sudo update-alternatives --install /usr/local/cuda cuda /usr/local/cuda-12.8 128 # now select it sudo update-alternatives --config cuda # we can also manually create the symlink sudo rm /etc/alternatives/cuda sudo ln -s /usr/local/cuda-12.8 /etc/alternatives/cuda sudo rm /usr/local/cuda sudo ln -s /etc/alternatives/cuda /usr/local/cuda # confirm ls -al /usr/local/cuda ls -al /etc/alternatives/cuda # should display /usr/local/cuda -\u003e /etc/alternatives/cuda /etc/alternatives/cuda -\u003e /usr/local/cuda-12.8 CUDA Runtime API The CUDA Runtime API is a set of functions that allow applications to interact with the GPU. The PyTorch binary we install already includes its own version of the necessary CUDA runtime files. Another example is cuda_runtime.h which we commonly used in cuda programming.\nThe diagram below shows the main components in cuda development toolkit.\nWhen we install packages like flash-attn, usually what we talk about is the CUDA version is CUDA toolkit version.\nnvidia-smi shows the nvidia driverâ€™s runtime version, NOT the CUDA libraries needed to compile or run GPU frameworks\nIn terms of compatibility, a newer NVIDIA driver (e.g., supporting CUDA 12.4) is generally backward-compatible with older CUDA Toolkits (e.g., CUDA 11.8).\nTwo-Stage Compilation of NVCC When we run CUDA codes, it goes through Source Code (CUDA C++) â†’ PTX â†’ CUBIN â†’ GPU Execution. Essentially NVCC adopts a two-stage compilation process.\nPTX (Parallel Thread Execution) â€” a virtual GPU architecture CUBIN (SASS) â€” actual hardware-specific binary for real GPUs Stage 1 â€” NVCC compiles CUDA code into PTX nvcc -arch=compute_80 kernel.cu â†’ kernel.ptx Here we choose a virtual architecture such as:\ncompute_50 compute_70 compute_90 These are not real GPU chips. They describe what CUDA features your code is allowed to use.\nStage 2 â€” PTX to machine code (CUBIN) nvcc -code=sm_80 kernel.cu â†’ kernel.cubin OR (if PTX is bundled):\nNVIDIA driver JIT â†’ sm_86 or future GPU Real GPUs have machine code defined by their SM architecture:\nsm_50, sm_70, sm_80, sm_90, etc. These architectures change with each GPU generation.\nPTX PTX (Parallel Thread Execution) is an intermediate representation (IR)\nA virtual GPU instruction set Abstract, stable, independent of real hardware Easy for compilers to target Similar to LLVM IR PTX is the secret that makes CUDA programs run on future GPUs. If CUDA only emitted native machine code, your program compiled in 2016 for Pascal (sm_60) would not run on a 2023 GPU like Ada Lovelace (sm_89).\nBut thanks to PTX:\nOld binaries contain PTX Driver JIT compiles PTX â†’ new architecture Your program keeps working without recompilation So, we can say that PTX = Forward Compatibility. CUDA chose a two-stage model for maintainability, performance, and long-term compatibility.\nReferences https://vutr.substack.com/p/the-overview-of-parquet-file-format ","wordCount":"568","inLanguage":"en-us","datePublished":"2023-05-05T00:18:23+08:00","dateModified":"2023-05-05T00:18:23+08:00","author":[{"@type":"Person","name":"Jun"}],"mainEntityOfPage":{"@type":"WebPage","@id":"https://rich-junwang.github.io/en-us/posts/tech/ml_infra/cuda/"},"publisher":{"@type":"Organization","name":"Jun's Blog","logo":{"@type":"ImageObject","url":"https://rich-junwang.github.io/img/Q.gif"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://rich-junwang.github.io/en-us/ accesskey=h title="Jun's Blog (Alt + H)"><img src=https://rich-junwang.github.io/img/Q.gif alt=logo aria-label=logo height=35>Jun's Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li></ul></div></div><ul id=menu><li><a href=https://rich-junwang.github.io/en-us/ title="ğŸ  Home"><span>ğŸ  Home</span></a></li><li><a href=https://rich-junwang.github.io/en-us/about title="ğŸ™‹ğŸ»â€â™‚ï¸ About"><span>ğŸ™‹ğŸ»â€â™‚ï¸ About</span></a></li><li><a href=https://rich-junwang.github.io/en-us/posts title="ğŸ“š Posts"><span>ğŸ“š Posts</span></a></li><li><a href=https://rich-junwang.github.io/en-us/tags title="ğŸ§© Tags"><span>ğŸ§© Tags</span></a></li><li><a href=https://rich-junwang.github.io/en-us/archives/ title="â±ï¸ Archives"><span>â±ï¸ Archives</span></a></li><li><a href=https://rich-junwang.github.io/en-us/search title="ğŸ” Search (Alt + /)" accesskey=/><span>ğŸ” Search</span></a></li></ul></nav></header><main class="main page"><style>i[id*=post_meta_style]{display:flex;align-items:center;margin:0 0 10px}</style><article class=post-single><div id=single-content><header class=post-header><div class=breadcrumbs><a href=https://rich-junwang.github.io/en-us/>ğŸ  Home</a>&nbsp;Â»&nbsp;<a href=https://rich-junwang.github.io/en-us/posts/>ğŸ“šArticles</a>&nbsp;Â»&nbsp;<a href=https://rich-junwang.github.io/en-us/posts/tech/>ğŸ‘¨ğŸ»â€ğŸ’» Tech</a></div><h1 class=post-title>CUDA</h1><div class=post-description>CUDA</div><div class=post-meta><style>i[id*=post_meta_style]{display:flex;align-items:center;margin:0 0 10px}.parent-post-meta{display:flex;flex-wrap:wrap;opacity:.8}</style><span class=parent-post-meta><span id=post_meta_style_1><span class="fa fa-calendar-check-o"></span>
<span>2023-05-05
&nbsp;&nbsp;
</span></span><span id=post_meta_style_3><span class="fa fa-file-word-o"></span>
<span>568 words
&nbsp;&nbsp;
</span></span><span id=post_meta_style_4><span class="fa fa-clock-o"></span>
<span>2 min
&nbsp;&nbsp;
</span></span><span id=post_meta_style_5><span class="fa fa-user-o"></span>
<span>Jun
&nbsp;&nbsp;
</span></span><span id=post_meta_style_6><span class="fa fa-tags" style=opacity:.8></span>
<span><span class=post-tags-meta><a href=https://rich-junwang.github.io/en-us/tags/cuda/ style=color:var(--secondary)!important>CUDA</a>
</span></span></span></span><span style=opacity:.8><span id=post_meta_style_7>&nbsp;&nbsp;
<span class="fa fa-eye"></span>
<span><span id=busuanzi_container_page_pv><span id=busuanzi_value_page_pv></span></span>
&nbsp;&nbsp;
</span></span><span id=post_meta_style_8><span class="fa fa-commenting-o"></span>
<span><script src=https://cdn.staticfile.org/twikoo/1.5.8/twikoo.all.min.js></script><script>let url=document.documentURI,dnsUrl="https://rich-junwang.github.io/",urlSplit=url.split(dnsUrl),finalUrl=urlSplit[1];finalUrl[0]!=="/"&&(finalUrl="/"+finalUrl),twikoo.getCommentsCount({envId:null,region:null,urls:[finalUrl],includeReply:!1}).then(function(e){let t=e[0].count;const n=document.getElementById("comment_count");n.innerText=t}).catch(function(e){console.error(e)})</script><span id=comment_count></span></span></span></span></div></header><aside id=toc-container class="toc-container wide"><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#cuda-ecosystem aria-label="CUDA Ecosystem">CUDA Ecosystem</a><ul><li><a href=#cuda-toolkit-libraries-and-compiler aria-label="CUDA Toolkit (Libraries and Compiler)">CUDA Toolkit (Libraries and Compiler)</a></li><li><a href=#cuda-runtime-api aria-label="CUDA Runtime API">CUDA Runtime API</a></li></ul></li><li><a href=#two-stage-compilation-of-nvcc aria-label="Two-Stage Compilation of NVCC">Two-Stage Compilation of NVCC</a><ul><li><a href=#stage-1--nvcc-compiles-cuda-code-into-ptx aria-label="Stage 1 â€” NVCC compiles CUDA code into PTX">Stage 1 â€” NVCC compiles CUDA code into PTX</a></li><li><a href=#stage-2--ptx-to-machine-code-cubin aria-label="Stage 2 â€” PTX to machine code (CUBIN)">Stage 2 â€” PTX to machine code (CUBIN)</a></li><li><a href=#ptx aria-label=PTX>PTX</a></li></ul></li><li><a href=#references aria-label=References>References</a></li></ul></div></details></div></aside><script>let activeElement,elements;window.addEventListener("DOMContentLoaded",function(){checkTocPosition(),elements=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]"),activeElement=elements[0];const t=encodeURI(activeElement.getAttribute("id")).toLowerCase();document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active")},!1),window.addEventListener("resize",function(){checkTocPosition()},!1),window.addEventListener("scroll",()=>{elements&&(activeElement=Array.from(elements).find(e=>{if(getOffsetTop(e)-window.pageYOffset>0&&getOffsetTop(e)-window.pageYOffset<window.innerHeight/2)return e})||activeElement,elements.forEach(e=>{const t=encodeURI(e.getAttribute("id")).toLowerCase();e===activeElement?document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active"):document.querySelector(`.inner ul li a[href="#${t}"]`).classList.remove("active")}))},!1);const main=parseInt(getComputedStyle(document.body).getPropertyValue("--article-width"),10),toc=parseInt(getComputedStyle(document.body).getPropertyValue("--toc-width"),10),gap=parseInt(getComputedStyle(document.body).getPropertyValue("--gap"),10);function checkTocPosition(){const e=document.body.scrollWidth;e-main-toc*2-gap*4>0?document.getElementById("toc-container").classList.add("wide"):document.getElementById("toc-container").classList.remove("wide")}function getOffsetTop(e){if(!e.getClientRects().length)return 0;let t=e.getBoundingClientRect(),n=e.ownerDocument.defaultView;return t.top+n.pageYOffset}</script><div class=post-content><h2 id=cuda-ecosystem>CUDA Ecosystem<a hidden class=anchor aria-hidden=true href=#cuda-ecosystem>#</a></h2><h3 id=cuda-toolkit-libraries-and-compiler>CUDA Toolkit (Libraries and Compiler)<a hidden class=anchor aria-hidden=true href=#cuda-toolkit-libraries-and-compiler>#</a></h3><p>The CUDA Toolkit contains the NVCC compiler and the development libraries (like cuBLAS, cuDNN, and the core CUDA libraries). Those libraries build on top of runtime API to save developers from writing complex, performance-critical algorithms from scratch.</p><p>CUDA Toolkit Installation</p><p>Go to the link <a href=https://developer.nvidia.com/cuda-toolkit>here</a>. It will guide you to the following instructions. Note that select the cuda-toolkit version lower than the cuda driver version (from nvidia-smi).</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2404/x86_64/cuda-keyring_1.1-1_all.deb
</span></span><span style=display:flex><span>sudo dpkg -i cuda-keyring_1.1-1_all.deb
</span></span><span style=display:flex><span>sudo apt-get update
</span></span><span style=display:flex><span>sudo apt-get -y install cuda-toolkit-13-0
</span></span></code></pre></div><p>After the installation, adding the binary path into your PATH</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>export PATH<span style=color:#f92672>=</span><span style=color:#e6db74>${</span>PATH<span style=color:#e6db74>}</span>:/usr/local/cuda/bin
</span></span><span style=display:flex><span>export LD_LIBRARY_PATH<span style=color:#f92672>=</span><span style=color:#e6db74>${</span>LD_LIBRARY_PATH<span style=color:#e6db74>}</span>:/usr/local/cuda/lib64
</span></span></code></pre></div><p>Check installation,</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>nvcc --version
</span></span></code></pre></div><p>If we have multiple cuda installed, we can use the following command to choose the default one</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>sudo update-alternatives --display cuda
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># If CUDA 12.8 is not listed as an option, add it:</span>
</span></span><span style=display:flex><span>sudo update-alternatives --install /usr/local/cuda cuda /usr/local/cuda-12.8 <span style=color:#ae81ff>128</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># now select it</span>
</span></span><span style=display:flex><span>sudo update-alternatives --config cuda
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># we can also manually create the symlink</span>
</span></span><span style=display:flex><span>sudo rm /etc/alternatives/cuda
</span></span><span style=display:flex><span>sudo ln -s /usr/local/cuda-12.8 /etc/alternatives/cuda
</span></span><span style=display:flex><span>sudo rm /usr/local/cuda
</span></span><span style=display:flex><span>sudo ln -s /etc/alternatives/cuda /usr/local/cuda
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># confirm</span>
</span></span><span style=display:flex><span>ls -al /usr/local/cuda
</span></span><span style=display:flex><span>ls -al /etc/alternatives/cuda
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># should display</span>
</span></span><span style=display:flex><span>/usr/local/cuda -&gt; /etc/alternatives/cuda
</span></span><span style=display:flex><span>/etc/alternatives/cuda -&gt; /usr/local/cuda-12.8
</span></span></code></pre></div><h3 id=cuda-runtime-api>CUDA Runtime API<a hidden class=anchor aria-hidden=true href=#cuda-runtime-api>#</a></h3><p>The CUDA Runtime API is a set of functions that allow applications to interact with the GPU. The PyTorch binary we install already includes its own version of the necessary CUDA runtime files. Another example is <code>cuda_runtime.h</code> which we commonly used in cuda programming.</p><p>The diagram below shows the main components in cuda development toolkit.</p><p>When we install packages like flash-attn, usually what we talk about is the CUDA version is CUDA toolkit version.</p><div align=center><img src=images/cuda.svg style=width:60%;height:auto></div><p><code>nvidia-smi</code> shows the nvidia driverâ€™s runtime version, NOT the CUDA libraries needed to compile or run GPU frameworks</p><p>In terms of compatibility, a newer NVIDIA driver (e.g., supporting CUDA 12.4) is generally backward-compatible with older CUDA Toolkits (e.g., CUDA 11.8).</p><h2 id=two-stage-compilation-of-nvcc>Two-Stage Compilation of NVCC<a hidden class=anchor aria-hidden=true href=#two-stage-compilation-of-nvcc>#</a></h2><p>When we run CUDA codes, it goes through Source Code (CUDA C++) â†’ PTX â†’ CUBIN â†’ GPU Execution. Essentially NVCC adopts a two-stage compilation process.</p><ol><li>PTX (Parallel Thread Execution) â€” a virtual GPU architecture</li><li>CUBIN (SASS) â€” actual hardware-specific binary for real GPUs</li></ol><h3 id=stage-1--nvcc-compiles-cuda-code-into-ptx>Stage 1 â€” NVCC compiles CUDA code into PTX<a hidden class=anchor aria-hidden=true href=#stage-1--nvcc-compiles-cuda-code-into-ptx>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>nvcc -arch=compute_80 kernel.cu â†’ kernel.ptx
</span></span></code></pre></div><p>Here we choose a <em>virtual architecture</em> such as:</p><ul><li><code>compute_50</code></li><li><code>compute_70</code></li><li><code>compute_90</code></li></ul><p>These are <em>not real GPU chips</em>. They describe what CUDA features your code is allowed to use.</p><h3 id=stage-2--ptx-to-machine-code-cubin>Stage 2 â€” PTX to machine code (CUBIN)<a hidden class=anchor aria-hidden=true href=#stage-2--ptx-to-machine-code-cubin>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>nvcc -code=sm_80 kernel.cu â†’ kernel.cubin
</span></span></code></pre></div><p>OR (if PTX is bundled):</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>NVIDIA driver JIT â†’ sm_86 or future GPU
</span></span></code></pre></div><p>Real GPUs have machine code defined by their SM architecture:</p><ul><li><code>sm_50</code>, <code>sm_70</code>, <code>sm_80</code>, <code>sm_90</code>, etc.</li></ul><p>These architectures change with each GPU generation.</p><h3 id=ptx>PTX<a hidden class=anchor aria-hidden=true href=#ptx>#</a></h3><p>PTX (Parallel Thread Execution) is an intermediate representation (IR)</p><ul><li>A virtual GPU instruction set</li><li>Abstract, stable, independent of real hardware</li><li>Easy for compilers to target</li><li>Similar to LLVM IR</li></ul><p>PTX is the secret that makes CUDA programs run on future GPUs. If CUDA only emitted native machine code, your program compiled in 2016 for Pascal (sm_60) would not run on a 2023 GPU like Ada Lovelace (sm_89).</p><p>But thanks to PTX:</p><ul><li>Old binaries contain PTX</li><li>Driver JIT compiles PTX â†’ new architecture</li><li>Your program keeps working without recompilation</li></ul><p>So, we can say that PTX = Forward Compatibility. CUDA chose a two-stage model for maintainability, performance, and long-term compatibility.</p><h2 id=references>References<a hidden class=anchor aria-hidden=true href=#references>#</a></h2><ol><li><a href=https://vutr.substack.com/p/the-overview-of-parquet-file-format>https://vutr.substack.com/p/the-overview-of-parquet-file-format</a></li></ol></div><footer class=post-footer><nav class=paginav><a class=prev href=https://rich-junwang.github.io/en-us/posts/tech/ml/flash_attn/><span class=title>Â«</span><br><span>Flash Attention</span>
</a><a class=next href=https://rich-junwang.github.io/en-us/posts/tech/ml_infra/data_processing/><span class=title>Â»</span><br><span>Data Processing in Distributed Training</span></a></nav></footer></div><style>.comments_details summary::marker{font-size:20px;content:'ğŸ‘‰Comment';color:var(--content)}.comments_details[open] summary::marker{font-size:20px;content:'ğŸ‘‡Collapse';color:var(--content)}</style><div><details class=comments_details><summary style="cursor:pointer;margin:50px 0 20px;width:130px"><span style=font-size:20px;color:var(--content)>...</span></summary><div id=tcomment></div></details><script src=https://cdn.staticfile.org/twikoo/1.5.8/twikoo.all.min.js></script><script>twikoo.init({envId:null,el:"#tcomment",lang:"en-us",region:null,path:window.TWIKOO_MAGIC_PATH||window.location.pathname})</script></div></article></main><footer class=footer><span>Copyright
&copy;
2020-2026
<a href=https://rich-junwang.github.io/en-us/ style=color:#939393>Jun's Blog</a>
All Rights Reserved
</span><a href=https://beian.miit.gov.cn/ target=_blank style=color:#939393></a>&nbsp;
<span id=busuanzi_container><span class="fa fa-user"></span> <span id=busuanzi_value_site_uv></span>
<span class="fa fa-eye"></span> <span id=busuanzi_value_site_pv></span></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><span class=topInner><svg class="topSvg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
<span id=read_progress></span>
</span></a><script>document.addEventListener("scroll",function(){const t=document.getElementById("read_progress"),n=document.documentElement.scrollHeight,s=document.documentElement.clientHeight,o=document.documentElement.scrollTop||document.body.scrollTop;t.innerText=((o/(n-s)).toFixed(2)*100).toFixed(0)})</script><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>let mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>200||document.documentElement.scrollTop>200?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{(function(){document.cookie="change-themes="+escape("false")})(),document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.body.addEventListener("copy",function(e){if(window.getSelection().toString()&&window.getSelection().toString().length>50){let t=e.clipboardData||window.clipboardData;if(t){e.preventDefault();let n=window.getSelection().toString()+`\r

â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\r
ç‰ˆæƒå£°æ˜ï¼šæœ¬æ–‡ä¸ºã€ŒJun's Blogã€çš„åŸåˆ›æ–‡ç« ï¼Œéµå¾ªCC 4.0 BY-SAç‰ˆæƒåè®®ï¼Œè½¬è½½è¯·é™„ä¸ŠåŸæ–‡å‡ºå¤„é“¾æ¥åŠæœ¬å£°æ˜ã€‚\r
åŸæ–‡é“¾æ¥ï¼š`+location.href,s=window.getSelection().toString()+`\r

â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\r
ç‰ˆæƒå£°æ˜ï¼šæœ¬æ–‡ä¸ºã€ŒJun's Blogã€çš„åŸåˆ›æ–‡ç« ï¼Œéµå¾ªCC 4.0 BY-SAç‰ˆæƒåè®®ï¼Œè½¬è½½è¯·é™„ä¸ŠåŸæ–‡å‡ºå¤„é“¾æ¥åŠæœ¬å£°æ˜ã€‚\r
åŸæ–‡é“¾æ¥ï¼š`+location.href;t.setData("text/html",n),t.setData("text/plain",s)}}})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const s=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerText="copy";function i(){t.innerText="copied!",setTimeout(()=>{t.innerText="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){let t=e.textContent+`\r
â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\r
ç‰ˆæƒå£°æ˜ï¼šæœ¬æ–‡ä¸ºã€ŒJun's Blogã€çš„åŸåˆ›æ–‡ç« ï¼Œéµå¾ªCC 4.0 BY-SAç‰ˆæƒåè®®ï¼Œè½¬è½½è¯·é™„ä¸ŠåŸæ–‡å‡ºå¤„é“¾æ¥åŠæœ¬å£°æ˜ã€‚\r
åŸæ–‡é“¾æ¥ï¼š`+location.href;navigator.clipboard.writeText(t),i();return}const n=document.createRange();n.selectNodeContents(e);const s=window.getSelection();s.removeAllRanges(),s.addRange(n);try{document.execCommand("copy"),i()}catch{}s.removeRange(n)});let l=e.className.replaceAll("language-",""),n=document.createElement("div"),a=document.createElement("div"),r=document.createElement("div"),c=document.createElement("div"),o=document.createElement("div");o.innerText=l,n.setAttribute("class","mac-tool"),a.setAttribute("class","mac bb1"),r.setAttribute("class","mac bb2"),c.setAttribute("class","mac bb3"),o.setAttribute("class","language-type"),n.appendChild(a),n.appendChild(r),n.appendChild(c),n.appendChild(o),s.classList.contains("highlight")?(s.appendChild(t),s.appendChild(n)):s.parentNode.firstChild==s||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?(e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t),s.appendChild(n)):(e.parentNode.appendChild(t),s.appendChild(n)))})</script></body></html>